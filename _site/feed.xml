<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Metals, Magnets, and Miscellaneous Materials</title>
    <description>Blog Introduction to Computational Condensed Matter Physics</description>
    <link>/M4/</link>
    <atom:link href="/M4/feed.xml" rel="self" type="application/rss+xml" />
    <generator>Jekyll v2.4.0</generator>
    
      <item>
        <title>Monte Carlo Ferromagnet</title>
        <description>&lt;p&gt;Prerequisites: &lt;a href=&quot;/M4/numerics/Monte-Carlo.html&quot;&gt;Monte Carlo Calculation of pi&lt;/a&gt;, &lt;a href=&quot;/M4/numerics/MCMC.html&quot;&gt;Monte Carlo Markov Chain&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-physics&quot;&gt;The physics&lt;/h2&gt;

&lt;p&gt;What process turns liquid water into a solid?  As temperature lowers, materials transition from a regime where the desire to maximize entropy dominates to desiring to minimize energy.   In transitions like liquid-solid, the energy arises from atom-atom forces.  This problem falls into a category called first order phase transitions, which are difficult to study.&lt;/p&gt;

&lt;p&gt;Instead of looking at the liquid-solid problem to understand phase transitions, we will look at a magnetic material undergoing a second order phase transition. In our approximation of the problem, the atoms exist at fixed positions on a lattice, and interact with their neighbor according to the following Hamiltonian,
\begin{equation}
    {\cal H} = -J \sum_{&amp;lt;i,j&amp;gt;} S^z_i S_j^z
\end{equation}
, which is basically just the energy.  This &lt;i&gt;Ising&lt;/i&gt; Model has nearest neighbors interacting, and each spin variablesolely points in the $\pm z$ direction.&lt;/p&gt;

&lt;p&gt;At a given temperature $T$, inverse temperature $\beta=1/T$, $k_b=1$, the occupancy of a given configuration $c_i$ follows the Maxwell-Boltzmann Probability Distribution,
\begin{equation}
P(c_i)=\frac{\mathrm{e}^{-\beta E(c_i)}}{\sum\limits_j \mathrm{e}^{-\beta E(c_j)}}
\end{equation}
We need to determine observables given this probability distribution.&lt;/p&gt;

&lt;h2 id=&quot;the-numerics&quot;&gt;The Numerics&lt;/h2&gt;

&lt;p&gt;In the post on the Markov Chain, each state was a location on our grid.  Now our state is one configuration of all our $N$ spins.  That means for an Ising spin we have $2^N$ different configurations.  Yeah… We aren’t going to be exploring all of those.&lt;/p&gt;

&lt;p&gt;So how do we get from one state to the next?&lt;/p&gt;

&lt;p&gt;First, we choose a spin that we could flip.  This potential spin is chosen randomly for convenience’s sake.&lt;/p&gt;

&lt;p&gt;Then we use the &lt;b&gt;Metropolis-Hastings Algorithm&lt;/b&gt; to decide whether or no to flip the spin and generate a new configuration.&lt;/p&gt;

&lt;p&gt;We split the solution into two cases based on $\alpha = \frac{\pi_i}{\pi_j}= \frac{P(c_i)}{P(c_j)}$:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If $\alpha &amp;gt; 1$ then always accept the transition, $p_{i \to j} = 1$&lt;/li&gt;
  &lt;li&gt;If $\alpha &amp;lt; 1$, accept the transition with probability $\alpha = p_{i \to j}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;b&gt;Does this obey detailed balance? &lt;/b&gt;&lt;/p&gt;

&lt;p&gt;From the Monte Carlo Markov Chain post, we take our equation for detailed balance&lt;/p&gt;

&lt;p&gt;\begin{equation}
\frac{p&lt;em&gt;{i \to j}}{ p&lt;/em&gt;{j \to i}} = \frac{\pi_i}{\pi_j}
\end{equation}&lt;/p&gt;

&lt;p&gt;How about ergodicity? We can reach any configuration by flipping spins.&lt;/p&gt;

&lt;p&gt;For the Ising Ferromagnet, our $\alpha$ is
\begin{equation}
\alpha= \frac{Z}{Z} \frac{\mathrm{e}^{-\beta E_i}}{\mathrm{e}^{-\beta E_j}}
= \mathrm{e}^{\beta \left(E_j - E_i \right)}
\end{equation}
which is simply a function of difference in energy between two states.  Therefore we don’t need to know the absolute energy at each point in time, just how the spin flip changes its local environment.&lt;/p&gt;

&lt;h2 id=&quot;tunable-parameters&quot;&gt;Tunable Parameters&lt;/h2&gt;

&lt;p&gt;I will say a little bit about the tunable parameters here, but Monte Carlo simulations are as much an art as a science, so I leave it up to you to play with the numbers and build intuition for what works.&lt;/p&gt;

&lt;h3 id=&quot;temperature&quot;&gt;Temperature&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;M4/Images/Ferromagnet/couch1.JPG&quot; width=&quot;200px&quot; style=&quot;float: left; margin: 20px&quot; /&gt; &lt;img src=&quot;M4/Images/Ferromagnet/mountain.jpg&quot; width=&quot;200px&quot; style=&quot;float: right; margin: 20px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On the left I am performing a low temperature search of a couch store.  I found a minimum, and even though I got stuck there, I thoroughly got to know what that minimum had to offer. On the right though, I’m performing a high temperature search of the Alexander Hills, Death Valley, California in pursuit of Neoproterzoic carbonates and dimictites.  I needed to be able to explore a lot more of the environment.&lt;/p&gt;

&lt;p&gt;While in a physical system like a magnet, temperature has a physical meaning, we can create other types of situations, like optimization or approximating a probability distribution, where we use temperature to describe how stuck we are to a particular minimum.  This intuition also plays a role in interpreting the results of of our simulation.&lt;/p&gt;

&lt;p&gt;Temperature can also provide other complications when we are studying critical phenomena, phase transitions.  Near the critical temperature, computations get much more difficult.  Elaboration in later post.&lt;/p&gt;

&lt;h3 id=&quot;size-of-lattice&quot;&gt;Size of Lattice&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Larger lattice gives more precise results.&lt;/li&gt;
  &lt;li&gt;Larger lattice takes more memory and time.&lt;/li&gt;
  &lt;li&gt;Finite Size effects, to be disscussed later, display some interesting physics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;coupling-constant-j&quot;&gt;Coupling Constant J&lt;/h3&gt;

&lt;p&gt;Usually normalized out anyway…&lt;/p&gt;

&lt;h3 id=&quot;number-of-time-steps&quot;&gt;Number of time steps&lt;/h3&gt;

&lt;p&gt;Each Monte Carlo time step is one complete sweep of the lattice, $N$ random flip attempts.  The more time steps, the more accurate the results, but the longer you have to wait.&lt;/p&gt;

&lt;h3 id=&quot;when-to-measure&quot;&gt;When to Measure&lt;/h3&gt;

&lt;p&gt;Though a time step does include $N$ spin flips, that doesn’t mean we have actually moved to a truly new configuration.  If we want to randomly sample our configuration space, we need to wait a bit longer to sample.  Too short a time, and our measurements are coupled and not accurate.  Too long, and we are wasting computations.  In a later post, I will look at the autocorrelation time, which is a good way to figure our if your measurement time is good.&lt;/p&gt;

&lt;h3 id=&quot;other-potential-options&quot;&gt;Other potential Options&lt;/h3&gt;

&lt;p&gt;Some less important things: periodic versus open boundary conditions, shape and symmetries of simulation cell.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
using PyPlot;
push!(LOAD_PATH,&quot;.&quot;)
using Lattices;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Instead of going into calculating all the lattice parameters again, we will use a class I define in the file Lattices.jl .  This class contains&lt;/p&gt;

&lt;p&gt;Lattice Types&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Chain&lt;/li&gt;
  &lt;li&gt;Square&lt;/li&gt;
  &lt;li&gt;Honeycomb
You can edit the file to make your own types.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once a lattice is created, it contains &lt;b&gt;Members of Type&lt;/b&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;name&lt;/code&gt;, a string&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;l&lt;/code&gt;, length in number of unit cells&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;dim&lt;/code&gt;, dimension of lattice&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;a&lt;/code&gt;, array containing the basis vectors by which positions are generated&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;unit&lt;/code&gt;, array of positions inside a single unit&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;N&lt;/code&gt;, number of total sites&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;X&lt;/code&gt;, array of positions&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;nnei&lt;/code&gt;, number of nearest neighbors&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;neigh&lt;/code&gt;, Array of nearest neighbors [i][j], where i is site and j is 1:nnei&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Today, I will just look at the square lattice, since that indicates much of the standard phase transition properties.  Some of the lattices I have shown (kagome, triangular, …) are special frustrated lattices, and thus will behave very wierdly in this situation.&lt;/p&gt;

&lt;p&gt;```julia
## Define l here
l=50;&lt;/p&gt;

&lt;p&gt;lt=MakeLattice(“Square”,l);
S=ones(Int8,l,l);  #Our spins
dt=1/(lt.N);
```&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
# The energy contribution of just one site
function dE(i::Int)
    Eii=0;
    for j in 1:lt.nnei
        Eii+=S[lt.neigh[i,j]];
    end
    Eii*=-J*S[i];  # we are computing J sz_i sz_j for one i
    return Eii;
end
# The energy of the entire lattice
function E()
    Evar=0;
    for k in 1:lt.N
        Evar+=.5*dE(k);
    end
    return Evar;
end
# The magnetization of the entire lattice
function M()
    Mvar=0;
    for k in 1:lt.N
        Mvar+=S[k];
    end
    return Mvar;
end
&quot;defined functions&quot;
&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;adjustable-parameters&quot;&gt;Adjustable Parameters&lt;/h1&gt;

&lt;p&gt;I have set up the simulation so that you can perform two different things.  For one, you can set &lt;code&gt;video=true&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt; to a small variable.  Then in a new window you see what the configuration looks like each time you measure.&lt;/p&gt;

&lt;p&gt;Or you can set &lt;code&gt;video=false&lt;/code&gt; and &lt;code&gt;t&lt;/code&gt; to a large variable, and actually measure the statistics for the system over a bunch of configurations.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
beta=.7;
J=1;
t=100000;
video=false;
nskip=10;   # don&#39;t measure every sweep= better decorrelation
&quot;Parameters set&quot;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
nmeas=Int64(t/nskip); # how many times we will measure
Ma=Array{Int32}(nmeas); # our magnetization measurements
Ea=Array{Int32}(nmeas); # our energy measurements
&quot;done&quot;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
tm=1; #Our measurement time step
pygui(true)
for ti in 1:t
    for j in 1:lt.N
        i = rand(1:lt.N); #Choosing a random site
        de=dE(i);
        if(de&amp;gt;0 || rand()&amp;lt;exp(2&lt;em&gt;beta&lt;/em&gt;de) )
            S[i]=-S[i]; #Switch the sign
        end
    end
    if isapprox(mod(ti,nskip),0)
        Ma[tm]=M();
        Ea[tm]=E();
        tm+=1;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    if video==true
        pygui(true)
        pcolor(S,cmap=&quot;winter&quot;)
        magnow=round(M()/lt.N,3)
        title(&quot;t: $ti  M: $magnow &quot;)
        draw()
        sleep(.5)
        #nm=dec(ti,4)
        #savefig(&quot;Magnetimages2/pic_l50_bp7_$nm.png&quot;)
    end
end end Mave=mean(Ma/lt.N); Mstd=std(Ma/lt.N); Eave=mean(Ea/lt.N); Estd=std(Ea/lt.N); Mave, Mstd ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;julia
pygui(false)
title(&quot;Magnetization versus Time, Beta=$beta&quot;)
xlabel(&quot;Monte Carlo Steps&quot;)
ylabel(&quot;Average Magnetization&quot;)
plot(collect(1:10:5000),Ma[1:500]/lt.N)
annotate(&quot; White Noise = Well Mixing&quot;,
xy=[500, Mave ],
xytext=[1000, Mave-.0125],
    xycoords=&quot;data&quot;,
    arrowprops=Dict(&quot;facecolor&quot;=&amp;gt;&quot;green&quot;))
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
pygui(false)
plt[:hist](Ma/lt.N,bins=30,normed=true,label=&quot;Samples Normed&quot;);
x=collect(Mave-Mstd*3:.001:Mave+Mstd*3)
gaussian=1/(Mstd*sqrt(2*pi))*exp(-(x-Mave).^2/(2*Mstd^2));
plot(x,gaussian,linewidth=5,label=&quot;Gaussian Fit&quot;)
title(&quot;Magnetization Sample Distribution beta=$beta&quot;)
xlabel(&quot;Mangetization&quot;)
ylabel(&quot;Normed Counts&quot;)
legend(loc=&quot;upper right&quot;)
#savefig(&quot;Ferromagnet/maghist_bp3.png&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
pygui(false)
title(&quot;Energy versus Time, Beta=$beta&quot;)
xlabel(&quot;Monte Carlo Steps&quot;)
ylabel(&quot;Average Energy&quot;)
plot(collect(1:10:5000),Ea[1:500]/lt.N)
annotate(&quot; White Noise = Well Mixing&quot;,
    xy=[500, Eave ],
xytext=[1000, Eave-.03],
   xycoords=&quot;data&quot;,
   arrowprops=Dict(&quot;facecolor&quot;=&amp;gt;&quot;green&quot;))
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
pygui(false)
plt[:hist](Ea/lt.N,bins=30,normed=true,label=&quot;Samples Normed&quot;);
x=collect(Eave-3*Estd:.001:Eave+3*Estd)
gaussian=1/(Estd*sqrt(2*pi))*exp(-(x-Eave).^2/(2*Estd^2));
plot(x,gaussian,linewidth=5,label=&quot;Gaussian Fit&quot;)
title(&quot;Energy Histogram, beta=$beta&quot;)
xlabel(&quot;Energy&quot;)
ylabel(&quot;Normed Counts&quot;)
#savefig(&quot;Ferromagnet/Ehist_bp3.png&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;example-results&quot;&gt;Example Results&lt;/h1&gt;
&lt;p&gt;So here are some example results I got.&lt;/p&gt;

&lt;p&gt;{ß include image.html img=”M4/Images/Ferromagnet/ParamagnetL30_b2.gif” title=”Paramagnet” caption=”States of a Paramagnet at $\beta=0.2$” %}&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Ferromagnet/mt.png&quot; alt=&quot;Samples over Time&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Paramagnet Magnetization Samples.  A properly tuned simulations should be showing white noise without correlations or getting stuck in particular areas.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;//maghist_bp3.png&quot; alt=&quot;Magnetization Histogram&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Magnetization Histogram&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Ferromagnet/Ehist_bp3.png&quot; alt=&quot;Energy Histogram&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Energy Histogram&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Ferromagnet/Magnet_betap7.gif&quot; alt=&quot;Magnet&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;States of a Paramagnet at $\beta=0.7$&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;Histogram for Magnetization
&lt;!-- _includes/image.html --&gt;
&amp;lt;div class=&quot;image-wrapper&quot; &amp;gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;img src=&quot;/M4/Images/Ferromagnet/maghist_bp7.png&quot; alt=&quot;Magnet Histogram&quot; /&amp;gt;


    &amp;lt;p class=&quot;image-caption&quot;&amp;gt;Histogram of a magnetization at $\beta=0.7$&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Ferromagnet/Ehist_bp7.png&quot; alt=&quot;Energy Histogram&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Histogram of energy at $\beta=0.7$&lt;/p&gt;
    
&lt;/div&gt;

&lt;h1 id=&quot;to-be-covered-later&quot;&gt;To be covered later:&lt;/h1&gt;

&lt;p&gt;This is an extremely rich problem.  Since this post seems long enough for me already, I’ll leave these to exercises for you right now, or you can wait until I hold your hand through them.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Plot magnetization and energy as a function of temperature&lt;/li&gt;
  &lt;li&gt;What’s the transition temperature?&lt;/li&gt;
  &lt;li&gt;How does the dispersion change as a function of temperature? Use that to calculate specific heat and susceptibility&lt;/li&gt;
  &lt;li&gt;How do results change with system size?&lt;/li&gt;
  &lt;li&gt;Change dimension?&lt;/li&gt;
  &lt;li&gt;Put it on a different lattice.  BE CAREFUL of lattices like triangular, checkerboard, pyrochlore, …&lt;/li&gt;
  &lt;li&gt;Ferromagnetic versus Antiferromagnetic coupling&lt;/li&gt;
  &lt;li&gt;Autocorrelation function&lt;/li&gt;
  &lt;li&gt;Structure Factorm, Fourier Transform&lt;/li&gt;
&lt;/ul&gt;
</description>
        <link>/M4/prerequisites/Monte-Carlo-Ferromagnet.html</link>
        <guid isPermaLink="true">/M4/prerequisites/Monte-Carlo-Ferromagnet.html</guid>
        
        <category>Magnet</category>
        
        
        <category>prerequisites</category>
        
      </item>
    
      <item>
        <title>HDF5 in Julia</title>
        <description>&lt;p&gt;So, last summer, my program was producing three dimensional data, and I needed a way to export and save that data from my C++ program.  Simple ASCII files, my default method, no longer covered my needs.  Of course, I wasn’t the first person to encounter this problem, so I discovered the HDF5 standard.&lt;/p&gt;

&lt;p&gt;Instead of storing data in a human readable format like ASCII, the Hierarchical Data Format, HDF, stores data in binary format.  This preserves the shape of the data in the computer and keeps it at its minimum size.  WOHOO!!&lt;/p&gt;

&lt;p&gt;Sadly, the syntax for HDF5 in C++ and Fortran is just as bad as FFTW or OpenBLAS.  But happily, just like FFTW and OpenBLAS, HDF5 has wonderful syntax in Julia, Python, and MATLAB, among others.&lt;/p&gt;

&lt;p&gt;So how does it work?&lt;/p&gt;

&lt;p&gt;We don’t just print a single variable.  Each HDF5 file is like its own file system.  In my home directory, I have my documents folder, my programming folder, my pictures, configuration files,… and inside each folder I can have subfolders or files.&lt;/p&gt;

&lt;p&gt;The same is true for an HDF5 file.  We have the root, and then we have groups and subgroups.  A group is like a folder.  Then we can have datasets. Datasets are objects that hold data (files).&lt;/p&gt;

&lt;h2 id=&quot;installing-the-package&quot;&gt;Installing the Package&lt;/h2&gt;

&lt;p&gt;While running &lt;code&gt;Pkg.add(&quot;HDF5&quot;);&lt;/code&gt; should hopefully add the HDF5 library, additional steps may be required.  I remember having a horrible time with the HDF installation when using C++ a year ago.  If at all possible, just use a package manager, and do not try and install it from source! See the HDF5.jl or HDFGroup pages for details.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
using HDF5;
&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;hello-world&quot;&gt;Hello World&lt;/h1&gt;
&lt;p&gt;Firstly, lets open a file and then write some data to it.&lt;/p&gt;

&lt;p&gt;We can open a file in three ways:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Symbol&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;“w”&lt;/td&gt;
      &lt;td&gt;Write.  Will overwrite anything already there.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;“r”&lt;/td&gt;
      &lt;td&gt;Ready-only.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;“r+”&lt;/td&gt;
      &lt;td&gt;Read-write. Preserving existing contents.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If we open with this syntax, we have to always remember to close it with &lt;code&gt;close()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
fid=h5open(“test.h5”,”w”)&lt;/p&gt;

&lt;p&gt;fid[“string”]=”Hello World”&lt;/p&gt;

&lt;p&gt;close(fid)
```&lt;/p&gt;

&lt;h3 id=&quot;navigating-a-file&quot;&gt;Navigating a File&lt;/h3&gt;

&lt;p&gt;Now lets see if we were successful by reading.  Instead of reading the dataset, we are going to checkout the structure of the file first.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;names(fid)&lt;/code&gt; tells us what is inside the location &lt;code&gt;fid&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;dump(fid)&lt;/code&gt; is much more in depth, exploring everything below &lt;code&gt;fid&lt;/code&gt;.  If we had a bunch of subdirectories, it would go down each one to see what was there.&lt;/p&gt;

&lt;p&gt;Both these functions help you find your way around a file.&lt;/p&gt;

&lt;p&gt;```julia
fid=h5open(“test.h5”,”r”)&lt;/p&gt;

&lt;p&gt;println(“names \n”,names(fid))&lt;/p&gt;

&lt;p&gt;println(“\n dump”)
println(dump(fid))&lt;/p&gt;

&lt;p&gt;close(fid)
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;names
Union{ASCIIString,UTF8String}[&quot;string&quot;]

 dump
HDF5.HDF5File len 1
  string: HDF5Dataset () : Hello World
nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;reading-data&quot;&gt;Reading Data&lt;/h3&gt;
&lt;p&gt;Now when we are reading data, we need to know the difference between dataset and the data the dataset contains.&lt;/p&gt;

&lt;p&gt;Look at the below example&lt;/p&gt;

&lt;p&gt;```julia
fid=h5open(“test.h5”,”r”)&lt;/p&gt;

&lt;p&gt;dset=fid[“string”]
println(“the dataset: \t”, typeof(dset))&lt;/p&gt;

&lt;p&gt;data=read(dset)
println(“the string: \t”, typeof(data),”\t”,data)&lt;/p&gt;

&lt;p&gt;data2=read(fid,”string”)
println(“read another way: \t”, typeof(data2),”\t”,data2)&lt;/p&gt;

&lt;p&gt;close(fid)
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;the dataset: 	HDF5.HDF5Dataset
the string: 	ASCIIString	Hello World
read another way: 	ASCIIString	Hello World
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A dataset is like the filename “fairytale.txt”, so we then need to read the file to get “Once upon a time …”.&lt;/p&gt;

&lt;h3 id=&quot;groups&quot;&gt;Groups&lt;/h3&gt;
&lt;p&gt;I’ve talked about groups, but we haven’t done anything with them yet. Let’s make some!&lt;/p&gt;

&lt;p&gt;Here we use &lt;code&gt;g_create&lt;/code&gt; to create two groups, one inside the other.  For the subgroup, it’s parent is &lt;code&gt;g&lt;/code&gt;, so we have to create it at location &lt;code&gt;g&lt;/code&gt;.  Just like in a filesystem, it’s name/ path is nested within its parent’s path.&lt;/p&gt;

&lt;p&gt;```julia
fid=h5open(“test.h5”,”w”)&lt;/p&gt;

&lt;p&gt;g=g_create(fid,”mygroup”);
h=g_create(g,”mysubgroup”);&lt;/p&gt;

&lt;p&gt;println(dump(fid))&lt;/p&gt;

&lt;p&gt;println(“\n path of h:  “,name(h))&lt;/p&gt;

&lt;p&gt;close(fid)
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;HDF5.HDF5File len 1
  mygroup: HDF5.HDF5Group len 1
    mysubgroup: HDF5.HDF5Group len 0
nothing

 path of h:  /mygroup/mysubgroup
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;attributes&quot;&gt;Attributes&lt;/h3&gt;

&lt;p&gt;Say in a file I want to include the information that I ran the simulation with 100 sites, at 1 Kelvin, for 100,000 timesteps.  Instead of creating new datasets for each of these individual numbers, I can create attributes and tie them to either a group or a dataset.&lt;/p&gt;

&lt;p&gt;```julia
fid=h5open(“test.h5”,”w”)&lt;/p&gt;

&lt;p&gt;fid[“data”]=randn(3,3);&lt;/p&gt;

&lt;p&gt;attrs(fid[“data”])[“Temp”]=”1”;
attrs(fid[“data”])[“N Sites”]=”100”;&lt;/p&gt;

&lt;p&gt;close(fid)&lt;/p&gt;

&lt;p&gt;fid=h5open(“test.h5”,”r”)&lt;/p&gt;

&lt;p&gt;dset=fid[“data”];&lt;/p&gt;

&lt;p&gt;println(“typeof attrs: \t”, typeof(attrs(dset)))
println(“Temp: \t”,read( attrs(dset),”Temp”  ))
println(“N Sites: \t”,read(  attrs(dset),”N Sites”  ))&lt;/p&gt;

&lt;p&gt;close(fid)
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;typeof attrs: 	HDF5.HDF5Attributes
Temp: 	1
N Sites: 	100
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;final-tips&quot;&gt;Final Tips&lt;/h3&gt;

&lt;p&gt;Before diving in to learn how to use this, think about whether you need it or not.  How large and complex is your data?  Is it worth the time to learn?  While the syntax might be relatively simple in Julia, ASCII files are still much easier to deal with.&lt;/p&gt;

&lt;p&gt;If you are going to play around or use this format, I recommend getting an HDF viewer, like &lt;a href=&quot;https://www.hdfgroup.org/products/java/release/download.html&quot;&gt;HDFViewer&lt;/a&gt;. While you can have much more control via code, sometimes it is just that much simpler to check everything is working with a GUI.&lt;/p&gt;

&lt;p&gt;For more information, checkout the Package page at &lt;a href=&quot;https://github.com/JuliaLang/HDF5.jl&quot;&gt;HDF5.jl&lt;/a&gt; or the HDFGroup page at &lt;a href=&quot;https://www.hdfgroup.org/&quot;&gt;HDFGroup&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I’ve shown some of the basic functionality in simple test cases.  If you want more control, you might just have to work a bit for it.&lt;/p&gt;
</description>
        <link>/M4/programming/HDF5.html</link>
        <guid isPermaLink="true">/M4/programming/HDF5.html</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Julia with MKL on OSX</title>
        <description>&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;One of the great things about Julia for those in scientific computing is the ease of accessing highly optimized libraries.  For matrix operations, Julia comes inbuilt with OpenBLAS, an open source implementation of BLAS, the Basic Linear Algebra Subprograms.  &lt;/p&gt;

&lt;p&gt;For the majority of people, that’s wonderful. OpenBLAS is quite fast and optimized.  &lt;/p&gt;

&lt;p&gt;BUT, when you want to diagonalize the large matrices that I do, there’s something better, Intel’s Math Kernel Library, MKL.  &lt;/p&gt;

&lt;p&gt;As Intel designed the chips and the hardware drivers for just about everyone, they can design their implementation of BLAS to take advantage of the specifics of the hardware and get a speed boost.  More to my purposes, it also doesn’t start aborting on larger matrices, even though I had plenty of RAM left.  The downside: they get this boost from trade secrets, and thus the software is propriety and behind closed doors.  Moral objections for some, monetary objections for others.&lt;/p&gt;

&lt;p&gt;If you want to get MKL for yourself, you have two possible routes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A free community license through &lt;a href=&quot;https://software.intel.com/sites/campaigns/nest/&quot;&gt;Intel Aviary&lt;/a&gt; . I got this for my workstation.  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Convince your company/ university/ institute to get the fully supported and expensive version. For example, my institute’s cluster has all of Intel’s tools.  &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;do-you-need-this&quot;&gt;Do you need this?&lt;/h1&gt;

&lt;p&gt;Before you start trying to implement this on your system, take a second and decide whether or not it is worth your while.   What kind of systems are you trying to diagonalize? Are you going to be diagonalizing systems at all?  Or multiplying large matrices… that would count too…&lt;/p&gt;

&lt;p&gt;I generated matrices through &lt;code&gt;A=randn(n,n);&lt;/code&gt; and then diagonalized them through &lt;code&gt;@time eigfact(A);&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;All of these specs are for my Mac Pro, Late 2013 model, running OSX El Capitan.  Processor: 3.7 GHz Quad-Core Intel Xeon E5.  Memory: 64 GB 1866 MHz DDR3 ECC.  I would be interested in seeing data for other processors.   &lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MKL/timescaling.png&quot; alt=&quot;Time Scaling&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Time scaling for MKL and OpenBLAS.  Performed for a matrix with randomly generated values according to a normal distribution of unit standard deviation.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MKL/factorscaling.png&quot; alt=&quot;Factor Scaling&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;The ratio between OpenBLAS and MKL.  While comporable at small system sizes, at larger matrices, MKL shows a significant improvement.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MKL/memoryscaling.png&quot; alt=&quot;Memory Scaling&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Both MKL and OpenBLAS showed the same memory usage for a given calculation.  The scaling appears quadratic, except for a deviation at small system sizes.&lt;/p&gt;
    
&lt;/div&gt;

&lt;h1 id=&quot;what-you-need-to-do&quot;&gt;What you need to do&lt;/h1&gt;

&lt;h3 id=&quot;for-intel&quot;&gt;For Intel&lt;/h3&gt;
&lt;p&gt;So in my &lt;code&gt;.zshrc&lt;/code&gt;, or &lt;code&gt;.bashrc&lt;/code&gt; for those who haven’t discovered the wonders of zsh, I now have&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
export TBBROOT=fdsljkfds
source /opt/intel/mkl/bin/mklvars.sh intel64 ilp64
&lt;/code&gt;
The value for &lt;code&gt;TBBROOT&lt;/code&gt; is non-zero gobblety-gook.&lt;br /&gt;
Once you have added that, either restart your terminal, or type&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
	source ~/.bashrc
&lt;/code&gt;
to refresh your terminal.  &lt;/p&gt;

&lt;p&gt;Now, check that these environment variables are set up correctly:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;MKLROOT&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/mkl&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;DYLD_LIBRARY_PATH&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/compiler/lib: /opt/intel//compilers_and_libraries_2016.2.146/mac/mkl/lib&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;LIBRARY_PATH&lt;/code&gt; 
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/compiler/lib: /opt/intel//compilers_and_libraries_2016.2.146/mac/mkl/lib&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;NLSPATH&lt;/code&gt; 
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/mkl/lib/locale/%l_%t/%N&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;MANPATH&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/man/en_US&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code&gt;CPATH&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;/opt/intel//compilers_and_libraries_2016.2.146/mac/mkl/include&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;by typing &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
echo $NAME_OF_VARIABLE
&lt;/code&gt;
Don’t just copy your variables against mine! Find your installation on the system, and checkout where the folders are.  &lt;/p&gt;

&lt;h3 id=&quot;for-the-julia-installation&quot;&gt;For the Julia Installation&lt;/h3&gt;
&lt;p&gt;In the Julia file, edit &lt;code&gt;Make.inc&lt;/code&gt; in this specific place &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
## Settings for various Intel tools
# Set to 1 to use MKL
USE_INTEL_MKL =1
# Set to 1 to use MKL FFT
USE_INTEL_MKL_FFT = 1
# Set to 1 to use Intel LIBM
USE_INTEL_LIBM ?= 0
# Set to 1 to enable profiling with Intel VTune Amplifier
USE_INTEL_JITEVENTS ?= 0
# Set to 1 to use Intel C, C++, and FORTRAN compilers
USEICC  ?= 0
USEIFC  ?= 0
&lt;/code&gt;
Now in the Julia folder try&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
make
make install
&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;how-i-eventually-figured-this-out&quot;&gt;How I eventually figured this out&lt;/h1&gt;
&lt;p&gt;I was getting complaints when &lt;code&gt;make&lt;/code&gt;ing Julia, that &lt;/p&gt;

&lt;p&gt;&lt;code&gt;
-L/opt/intel//compilers_and_libraries_2016.2.146/mac/tbb/lib
&lt;/code&gt;
wasn’t found.  There was good reason it wasn’t found. It didn’t exist.  TBB stands for Threading Building Blocks, another one of Intel’s programs, but this one is meant for multicore C++ programs.  Sounds fairly useful, but off topic to what I need right now.  &lt;/p&gt;

&lt;p&gt;So I wanted to figure out why it was trying to link to that directory.  Looking in &lt;code&gt;/opt/intel/mkl/bin/mklvars.sh&lt;/code&gt;, the program that sets environment variables for MKL, I discovered:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
                if [ -z &quot;${TBBROOT}&quot; ]; then
                    mkl_ld_arch=&quot;${CPRO_PATH}/tbb/lib:${mkl_ld_arch}&quot;
                fi
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;When the variable &lt;code&gt;TBBROOT&lt;/code&gt; is zero, it adds this &lt;code&gt;tbb&lt;/code&gt; folder to the path.   Since I can’t change that file, proprietary stuff, my work around is making &lt;code&gt;TBBROOT&lt;/code&gt; non-zero.  Then &lt;code&gt;DYLD_LIBRARY_PATH&lt;/code&gt;, which gets linked in the Julia &lt;code&gt;make&lt;/code&gt; processes, only contains good locations.  &lt;/p&gt;

&lt;p&gt;Also, you can’t just run &lt;code&gt;source ...&lt;/code&gt; to on the command line once and have the variables set for all eternity.  When I restarted my terminal the next day, the variables had cleared.  So I figured out the lines need to be put in the &lt;code&gt;~/.bashrc&lt;/code&gt; (or &lt;code&gt;~/.zshrc&lt;/code&gt;) instead of just run once. &lt;/p&gt;

&lt;h1 id=&quot;conculsions&quot;&gt;Conculsions&lt;/h1&gt;

&lt;p&gt;I still got warnings when making Julia, but obviously none that broke the installation.  Hopefully this work-around holds me over till this project is done, and hopefully it helps someone else too :)&lt;/p&gt;
</description>
        <link>/M4/programming/MKL.html</link>
        <guid isPermaLink="true">/M4/programming/MKL.html</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Monte Carlo Markov Chain</title>
        <description>&lt;p&gt;&lt;b&gt;Prerequisites:&lt;b&gt;&lt;/b&gt;  &lt;a href=&quot;/M4/numerics/Monte-Carlo.html&quot;&gt;Monte Carlo Calculation of pi&lt;/a&gt;&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Author:&lt;/b&gt; Christina Lee&lt;/p&gt;

&lt;h3 id=&quot;intro&quot;&gt;Intro&lt;/h3&gt;

&lt;p&gt;If you didn’t check it out already, take a look at the post that introduces using random numbers in calculations.  Any such simulation is a &lt;i&gt;Monte Carlo&lt;/i&gt; simulation.  The most used kind of Monte Carlo simulation is a &lt;i&gt;Markov Chain&lt;/i&gt;, also known as a random walk, or drunkard’s walk.  A Markov Chain is a series of steps where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;each new state is chosen probabilitically&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;the probabilities only depend on the current state, no memory.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Imagine a drunkard trying to walk.  At any one point, they could progress either left or right rather randomly.  Also, just because they had been traveling in a straight line so far does not guaruntee they will continue to do.  They’ve just had extremely good luck.&lt;/p&gt;

&lt;p&gt;We use Markov Chains to &lt;b&gt;approximate probability distributions&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;To create a good Markov Chain, we need&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt; Ergodicity&lt;/b&gt;: All states can be reached&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;b&gt; Global Balance&lt;/b&gt;: A condition that ensures the proper equilibrium distribution&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-balances&quot;&gt;The Balances&lt;/h3&gt;

&lt;p&gt;Let $\pi_i$ be the probability that a particle is at site $i$, and $p_{ij}$ be the probability that a particle moves from $i$ to $j$.  Then Global Balance can be written as,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\sum\limits_j \pi_i p_{i j} = \sum\limits_j \pi_j p_{j i} \;\;\;\;\; \forall i.
&lt;/script&gt;

&lt;p&gt;In non-equation terms, this says the amount of “chain” leaving site $i$ is the same as the amount of “chain” entering site $i$ for every site in equilibrium.  There is no flow.&lt;/p&gt;

&lt;p&gt;Usually though, we actually want to work with a stricter rule than Global Balance, &lt;b&gt; Detailed Balance &lt;/b&gt;, written as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\pi_i p_{i j} = \pi_j p_{j i}.
&lt;/script&gt;

&lt;p&gt;Detailed Balance further constricts the transition probabilities we can assign and makes it easier to design an algorithm. Almost all MCMC algorithms out there use detailed balance, and only lately have certain applied mathematicians begun looking and breaking detailed balance to increase efficiency in certain classes of problems.&lt;/p&gt;

&lt;h3 id=&quot;todays-test-problem&quot;&gt;Today’s Test Problem&lt;/h3&gt;

&lt;iframe width=&quot;400&quot; height=&quot;300&quot; src=&quot;https://www.youtube.com/embed/gxX3Fu1uuCs&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;I will let you know now; this might be one of the most powerful numerical methods you could ever learn.  I was going to put down a list of applications, but the only limit to such a list is your imagination.&lt;/p&gt;

&lt;p&gt;Today though, we will not be trying to predict stock market crashes, calculate the PageRank of a webpage, or calculate the entropy a quantum spin liquid at zero temperature.  We just want to calculate an uniform probability distribution, and look at how Monte Carlo Markov Chains behave.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;We will start with an $l\times l$ grid&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Our chain starts somewhere in that grid&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We can then move up, down, left or right equally&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If we hit an edge, we come out the opposite side&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;b&gt;First question!&lt;/b&gt; Is this ergodic?&lt;/p&gt;

&lt;p&gt;Yes! Nothing stops us from reaching any location.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Second question!&lt;/b&gt; Does this obey detailed balance?&lt;/p&gt;

&lt;p&gt;Yes!  In equilibrium, each block has a probability of $\pi_i = \frac{1}{l^2}$, and can travel to any of its 4 neighbors with probability of $p_{ij} = \frac{1}{4}$.  For any two neighbors&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{1}{l^2}\frac{1}{4} = \frac{1}{l^2}\frac{1}{4},
&lt;/script&gt;

&lt;p&gt;and if they are not neighbors,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
0 = 0.
&lt;/script&gt;

&lt;p&gt;&lt;code&gt;julia
#Pkg.add(&quot;PyCall&quot;)
using PyPlot
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is just the equivalent of &lt;code&gt;mod&lt;/code&gt;
for using in an array that indexes from 1.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
function armod(i,j)
    return (mod(i-1+j,j)+1)
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Input the size of the grid&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
l=3;
n=l^2;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
function Transition(i)
    #randomly chose up, down, left or right
    d=rand(1:4);
    if d==1 #if down
        return armod(i-l,n);&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;elseif d==2 #if left
    row=convert(Int,floor((i-1)/l));
    return armod(i-1,l)+l*row;

elseif d==3 #if right
    row=convert(Int,floor((i-1)/l));
    return armod(i+1,l)+l*row;

else  # otherwise up
    return armod(i+l,n);
end end ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The centers of blocks will be used for pictoral purposes&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
pos=zeros(Float64,2,n);
pos[1,:]=[floor((i-1)/l) for i in 1:n]+.5;
pos[2,:]=[mod(i-1,l) for i in 1:n]+.5;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
# How many timesteps
tn=1000;&lt;/p&gt;

&lt;h1 id=&quot;array-of-timesteps&quot;&gt;Array of timesteps&lt;/h1&gt;
&lt;p&gt;ti=Array{Int64,1}()
# Array of errors
err=Array{Float64,1}()&lt;/p&gt;

&lt;h1 id=&quot;stores-current-location-initialized-randomly&quot;&gt;Stores current location, initialized randomly&lt;/h1&gt;
&lt;p&gt;current=rand(1:n);
# Stores last location, used for pictoral purposes
last=current;&lt;/p&gt;

&lt;h1 id=&quot;keeps-track-of-where-chain-went&quot;&gt;Keeps track of where chain went&lt;/h1&gt;
&lt;p&gt;Naccumulated=zeros(Int64,l,l);&lt;/p&gt;

&lt;h1 id=&quot;put-in-our-first-point&quot;&gt;put in our first point&lt;/h1&gt;
&lt;p&gt;# can index 2d array as 1d
Naccumulated[current]+=1;&lt;/p&gt;

&lt;h1 id=&quot;a-graph-will-open-up-where-we-can-watch-the-chain&quot;&gt;A graph will open up where we can watch the chain&lt;/h1&gt;
&lt;p&gt;pygui(true)
w, h = plt&lt;a href=&quot;.35&quot;&gt;:figaspect&lt;/a&gt;
figure(figsize=(w,h))&lt;/p&gt;

&lt;p&gt;for ii in 1:tn&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;last=current;
# Determine the new point
current=Transition(current);
Naccumulated[current]+=1;

# add new time steps and error points
push!(ti,ii)
push!(err,round(std(Naccumulated/ii),5))


clf() #clean previous figure

subplot(121) #subplot 1

title(&quot;t: $ii std: $(err[end])&quot;)
pcolor(Naccumulated/ii-1/n,cmap=&quot;RdBu&quot;,vmin=-.1,vmax=.1)
colorbar()

# An arrow from the previous point to the current point
annotate(&quot;&quot;,
xy=pos[:,current],
xytext=pos[:,last],
xycoords=&quot;data&quot;,
arrowprops=Dict(&quot;facecolor&quot;=&amp;gt;&quot;green&quot;))

subplot(122) #subplot 2
title(&quot;Error&quot;)
xlabel(&quot;Step&quot;)
ylabel(&quot;Log std&quot;)
scatter(ti,log10(err))

#how long to wait between showing steps (in seconds)
sleep(.5) end Naccumulated=Naccumulated/tn; ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;julia
pygui(false)
pcolor(Naccumulated/tn-1/n,cmap=&quot;RdBu&quot;,vmin=-.02,vmax=.02)
colorbar()
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MCMC/grid5x5p.png&quot; alt=&quot;Grid&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;A 5x5 grid after 2,000 steps.  &lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;&lt;code&gt;julia
title(&quot;Error for a 5x5&quot;)
xlabel(&quot;Step&quot;)
ylabel(&quot;Log std&quot;)
scatter(ti,log10(err))
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MCMC/err5x5p.png&quot; alt=&quot;Error over time&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;The decreasing standard deviation from 1/25 shown in log base 10.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;So, after running the above code and trying to figure out how it works, go back and study some properties of the system.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;How long does it take to forget it’s initial position?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How does the behaviour change with system size?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How long would you have to go to get a certain accuracy? ….  especially if you didn’t know what distribution you where looking for&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So hopefully you enjoyed this tiny introduction to an incredibly rich subject.  Feel free to explore all the nooks and crannies to really understand the basics of this kind of simulation, so you can gain more control over the more complex simulations.&lt;/p&gt;

&lt;p&gt;Monte Carlo simulations are as much of an art as a science.  You need to live them, love them, and breathe them till you find out exactly why they are behaving like little kittens that can finally jump on top of your countertops, or open your bedroom door at 1am.&lt;/p&gt;

&lt;p&gt;For all their mishaving, you love the kittens anyway.&lt;/p&gt;
</description>
        <link>/M4/numerics/MCMC.html</link>
        <guid isPermaLink="true">/M4/numerics/MCMC.html</guid>
        
        <category>Monte Carlo</category>
        
        
        <category>numerics</category>
        
      </item>
    
      <item>
        <title>Monte Carlo Calculation of pi</title>
        <description>&lt;h2 id=&quot;monte-carlo--random-numbers-to-improve-calculations&quot;&gt;Monte Carlo- Random Numbers to Improve Calculations&lt;/h2&gt;

&lt;p&gt;When one hears “Monte Carlo”, most people might think of something like this:&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MonteCarlo/871.jpg&quot; alt=&quot;Monte Carlo&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;My Mom and I touring Monte Carlo, Monaco.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;Monte Carlo, Monaco: known for extremely large amounts of money, car racing, no income taxes,and copious gambling.&lt;/p&gt;

&lt;p&gt;In addition to Monaco, Europe, Las Vegas decided to host a Monte Carlo-themed casino as well.  So during the Manhattan project, when the best minds in the United States were camped out in the New Mexican desert, they had plenty of inspiration from Las Vegas, and plenty of difficult problems to work on in the form of quantifying the inner workings of nuclei.  Enrico Fermi first played with these ideas, but Stanislaw Ulam invented the modern Monte Carlo Markov Chain later.&lt;/p&gt;

&lt;p&gt;At the same time, these scientists now had computers at their disposal.  John von Neumann programmed Ulam’s algorithm onto ENIAC, Electronic Numerical Integrator and Computer, the very first electronic, general purpose computer, even though it did still run on vacuum tubes.&lt;/p&gt;

&lt;p&gt;That still doesn’t answer, why do random numbers actually help us solve problems?&lt;/p&gt;

&lt;p&gt;Imagine you are visiting a new city for the first time, maybe Monte Carlo. You only have a day or two, and you want to really get to know the city.  You have two options for your visit&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hit the tourist sites you researched online&lt;/li&gt;
  &lt;li&gt;Wander around.  Try and communicate with the locals.  Find an out-of-the-way restaurant and sample food not tamed for foreigners.  Watch people interact.  Get lost.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both are legitimate ways to see the city.  But depending on what you want, you might choose a different option.  The same goes for exploring physics problems.  Sometimes you want to go in and study just everything you knew about beforehand, but sometimes you need to wander around, not hit everything, but get a better feeling for what everything might be like.&lt;/p&gt;

&lt;h2 id=&quot;buffons-needle-calculation-of-&quot;&gt;Buffon’s Needle: Calculation of π&lt;/h2&gt;
&lt;p&gt;Even back in the 18th century, Georges-Louis Leclerc, Comte de Buffon posed a problem in geometric probability.  Nowdays, we use a slightly different version of that problem to calculate π and illustrate Monte Carlo simulations.&lt;/p&gt;

&lt;p&gt;Suppose we have a square dartboard, and someone with really bad, completely random aim, even though he/she always at least hits inside the dartboard.  We then inscribe a circle inside that dartboard. After an infinity number of hits, what is the ratio between hits in the circle, and hits in the square?&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MonteCarlo/dartboard.png&quot; alt=&quot;dartboard&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Randomly thrown darts than can either be in the circle or not.&lt;/p&gt;
    
&lt;/div&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
f= \frac{N_{circle}}{N_{square}} =\frac{\text{Area of circle}}{\text{Area of square}} =\frac{\pi r^2}{4 r^2}= \frac{\pi}{4}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
    \pi = 4 f
&lt;/script&gt;

&lt;h2 id=&quot;onto-the-code&quot;&gt;Onto the Code!&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;julia
#Pkg.update()
#Pkg.add(&quot;PyPlot&quot;)
using PyPlot
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;We will generate our random numbers on the unit interval.  Thus the radius in our circumstance is $.5$.&lt;/p&gt;

&lt;p&gt;Write a function &lt;code&gt;incircle(r2)&lt;/code&gt; such that if &lt;code&gt;r2&lt;/code&gt; is in the circle, it returns true, else, it returns false.  We will use this with the julia function &lt;code&gt;filter&lt;/code&gt;.  Assume &lt;code&gt;r2&lt;/code&gt; is the radius squared, and already centered around the middle of the unit circle&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
function incircle(r2)
    if r2&amp;lt;.25
        return true
    else
        return false
    end
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
#The number of darts we will throw at the board.  We will see how accurate different numbers are
N=[10,25,50,75,100,250,500,750,1000,2500,5000,7500,10000];
# We will perform each number multiple times in order to calculate error bars
M=15;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
πapprox=zeros(Float64,length(N),M);&lt;/p&gt;

&lt;p&gt;for ii in 1:length(N)
    #initialize an array of proper size
    X=zeros(Float64,N[ii],2);
    for jj in 1:M&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    #popular our array with random numbers on the unit interval
    rand!(X);

    #calculate their radius squared
    R2=(X[:,1]-.5).^2+(X[:,2]-.5).^2

    # 4*number in circle / total number
    πapprox[ii,jj]=4.*length(filter(incircle,R2))/N[ii];

end end ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;julia
# Get our averages and standard deviations
πave=sum(πapprox,2)/M;
πstd=std(πapprox,2);
&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;analysis&quot;&gt;Analysis&lt;/h2&gt;

&lt;p&gt;So that was a nice, short little piece of code.  Lets plot it now to see means.&lt;/p&gt;

&lt;p&gt;```julia
title(“Monte Carlo Estimation of π”)
ylabel(“π estimate”)
xlabel(“N points”)
plot(N,π*ones(N));&lt;/p&gt;

&lt;p&gt;for j in 1:M
    scatter(N,πapprox[:,j],marker=”o”,color=”green”);
end
ax=gca()
errorbar(N,π*ones(N),yerr=πstd,color=”red”,fmt=”o”)
ax&lt;a href=&quot;&amp;quot;log&amp;quot;&quot;&gt;:set_xscale&lt;/a&gt;;
ax&lt;a href=&quot;[5,5*10^4]&quot;&gt;:set_xlim&lt;/a&gt;;
```&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MonteCarlo/piestimation2.png&quot; alt=&quot;Result&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Image result.  I inverted the color scale though.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;When we have fewer numbers of points, our estimates vary much more wildly, and much further from 3.1415926 .
But, at least, the guesses from our different runs all seem equally distributed around the correct value, so it seems we have no systematic error.&lt;/p&gt;

&lt;p&gt;As we get up to $10^4$, our estimate starts getting much more accurate and consistent.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
title(&quot;Dependence of Monte Carlo Error on Number of Points&quot;)
ylabel(&quot;standard deviation&quot;)
xlabel(&quot;N points&quot;)
semilogx(N,πstd,marker=&quot;o&quot;);
&lt;/code&gt;
&lt;!-- _includes/image.html --&gt;
&amp;lt;div class=&quot;image-wrapper&quot; &amp;gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;img src=&quot;/M4/Images/MonteCarlo/error.png&quot; alt=&quot;Result&quot; /&amp;gt;


    &amp;lt;p class=&quot;image-caption&quot;&amp;gt;Image result. Colors tweaked.&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;

&lt;p&gt;So what we guessed in the first plot about dispersion in estimate, we quantify here in this plot.  When we only have 10 darts, the guesses vary by up to .3, but when we get down to 1,000 trials, we are starting to be consistent to .0002&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
title(&quot;Overall Averages&quot;)
xlabel(&quot;N steps&quot;)
ylabel(&quot;Average of 15 runs&quot;)
semilogx(N,π*ones(N));
semilogx(N,πave,marker=&quot;o&quot;);
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MonteCarlo/ave.png&quot; alt=&quot;Result&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Image result. Colors tweaked.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;Now lets just make a graphical representation of what we’ve been doing this whole time.  Plot our points on unit square, and color the ones inside a circle a different color.&lt;/p&gt;

&lt;p&gt;```julia
X=zeros(Float64,1000);
Y=zeros(Float64,1000);
rand!(X);
rand!(Y);
R2=(X-.5).^2+(Y-.5).^2;
Xc=[];
Yc=[]
for ii in 1:length(X)
    if R2[ii]&amp;lt;.25
        push!(Xc,X[ii]);
        push!(Yc,Y[ii]);
    end
end&lt;/p&gt;

&lt;p&gt;title(“The dartboard”)
xlim(0,1)
ylim(0,1)
scatter(X,Y);
scatter(Xc,Yc,color=”red”);
```&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MonteCarlo/dartboardpyplot.png&quot; alt=&quot;Result&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Result. Colors tweaked&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;That’s all folks!
Now here’s a picture of some pie to congratulate you on calculating π.
&lt;!-- _includes/image.html --&gt;
&amp;lt;div class=&quot;image-wrapper&quot; &amp;gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;img src=&quot;/M4/Images/MonteCarlo/pie.jpg&quot; alt=&quot;pie&quot; /&amp;gt;


    &amp;lt;p class=&quot;image-caption&quot;&amp;gt;By Scott Bauer, USDA ARS - This image was released by the Agricultural Research Service, the research agency of the United States Department of Agriculture, with the ID K7252-47 (next).This tag does not indicate the copyright status of the attached work. A normal copyright tag is still required. See Commons:Licensing for more information.English | français | македонски | +/−, Public Domain, https://commons.wikimedia.org/w/index.php?curid=264106&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;

</description>
        <link>/M4/numerics/Monte%20Carlo.html</link>
        <guid isPermaLink="true">/M4/numerics/Monte%20Carlo.html</guid>
        
        <category>Monte Carlo</category>
        
        
        <category>numerics</category>
        
      </item>
    
      <item>
        <title>Jacobi Transformation of a Symmetric Matrix</title>
        <description>&lt;p&gt;&lt;i&gt;Based on Numerical Recipes in C++, Sec 11.1&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;So you want to diagonalize a matrix, do you?
Well, if you have a tiny symmetric matrix, you REALLY want to write up the algorithm by hand, and don’t want to spend much time trying to understand the algorithm, then you have come to the right place.&lt;/p&gt;

&lt;p&gt;Otherwise, use LAPACK/BLAS to call a highly optimized routine that can work extremely quickly on large matrices. Julia has those libraries built in already. Even if you do call those matrices, you can make them work better by understanding what’s going on underneath the hood, which is why we are going through this now.&lt;/p&gt;

&lt;p&gt;Start with a base &lt;i&gt;rotation matrix&lt;/i&gt; of the Form
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[

    P_{pq} =
    \begin{pmatrix}
           1&amp; &amp;  &amp;  &amp; &amp; &amp; &amp; 0 \\
           &amp; \ddots &amp; &amp; &amp; &amp;  &amp;  \\
            &amp; &amp; c &amp; \cdots &amp; s &amp; &amp; \\
                &amp; &amp;\vdots&amp; 1 &amp; \vdots &amp; &amp; \\
               &amp; &amp; -s &amp; \cdots &amp; c &amp; &amp;  \\
               &amp; &amp; &amp; &amp; &amp; \ddots &amp;  \\
               0 &amp; &amp; &amp; &amp;  &amp; &amp; 1\\
    \end{pmatrix}
 %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;From our starting arbitrary symmetric &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt;,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
A^T = A
&lt;/script&gt;

&lt;p&gt;we will run a series of transformations,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
A^{\prime}= P^{T}\_{pq} \cdot A \cdot P\_{pq}
&lt;/script&gt;

&lt;p&gt;where each iteration brings &lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; closer to diagonal form.  Thus in our implementing our algorithm, we need to determine two things&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The values of &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;s&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;The pattern of sweeping &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And in the end we will need to finally determine if this actually converges, and if has any sort of efficiency.&lt;/p&gt;

&lt;p&gt;So lets expand one transformation, and we if we can solve for $c$ and $s$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{rp}  = c a_{rp} - s a_{rq}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{rq}  = c a_{rq} + s a_{rp}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{pp}  = c^2 a_{pp} + s^2 a_{qq} -2 sc a_{pq}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{qq}  = s^2 a_{qq} + c^2 a_{qq} + 2sc a_{pq}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{pq}  = \left( c^2-s^2 \right) a_{pq} + sc \left(a_{pq} - a_{qq} \right)
&lt;/script&gt;

&lt;h2 id=&quot;determining-s-and-c&quot;&gt;Determining $s$ and $c$&lt;/h2&gt;
&lt;p&gt;Given we specifically want $a^{\prime}_{pq}$ to be zero, we re-arrange the last equation,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
        \frac{c^2-s^2}{2 sc} = \frac{a_{pq}-a_{qq}}{2 a_{pq}} = \theta
&lt;/script&gt;

&lt;p&gt;At first glance, this equation might not look easier to solve for $s$ or $c$.  At second glance either. We define a new parameter $t = s/c$, which now makes the equation,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\frac{1-t^2}{2 t} = \theta \;\;\;\; \implies \;\;\; t^2 -2 \theta t -1=0,
&lt;/script&gt;

&lt;p&gt;now quite easily solvable by our friendly quadratic formula.  Though the book does recommend using a form that pulls out smaller roots through&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
t=\frac{\text{sgn}( \theta )}{| \theta | + \sqrt{ \theta ^2 + 1} }.
&lt;/script&gt;

&lt;p&gt;Then reverse solve back to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
c=\frac{1}{\sqrt{t^2+1}} \;\;\; s=tc
&lt;/script&gt;

&lt;p&gt;Though we could use the expressions above, if we simplify them with our new expressions for $c$ and $s$ analytically, we reduce computational load and round off error. These new expressions are&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{pq}  = 0
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{qq}  = a_{qq} + t a_{qp}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{pp} = a_{pp} - t a_{pq}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{rp} = a_{rp} - s \left( a_{rq} +\tau a_{rp} \right)
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
a^{\prime}_{rq} = a_{rq} + s \left( a_{rp} -\tau a_{rq} \right)
&lt;/script&gt;

&lt;p&gt;with the new variable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\tau = \frac{s}{1+c}
&lt;/script&gt;

&lt;h2 id=&quot;convergence&quot;&gt;Convergence&lt;/h2&gt;

&lt;p&gt;The sum of the squares of the off diagonal elements, choosen in either upper or lower triangles arbitrarily,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

S=\sum\limits_{r &lt; s} |a_{rs}|^2
 %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;eigenvectors&quot;&gt;Eigenvectors&lt;/h2&gt;

&lt;p&gt;By forming a product of every rotation matrix, we also come to approximate the matrix $V$ where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
D = V^{T} \cdot A \cdot V
&lt;/script&gt;

&lt;p&gt;and $D$ is the diagonal form of $A$.  $V$ is computed through iterative computation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
V^{\prime} = V \cdot P_i
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
v^{\prime}_{rs} = v_{rs}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
v^{\prime}_{rp} = c v_{rp} - s v_{rq}
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
v^{\prime}_{rq} = s v_{rp} + c v_{rq}
&lt;/script&gt;

&lt;h3 id=&quot;enough-with-the-talking-lets-compute-stuff&quot;&gt;Enough with the talking! LETS COMPUTE STUFF&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-julia&quot;&gt;# First, Lets make our nice, helpful functions

## A function to look at the convergence
function convergence(A::Array)
    num=0.0
    l=size(A)[1]
    for ii in 1:(l-1)
        for jj in (ii+1):l ## just looking at the lower triangle
            num+=A[ii,jj]^2
            #println(ii,&#39; &#39;,jj,&#39; &#39;,num,&#39; &#39;,A[ii,jj])
        end
    end
    return num
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This makes a matrix easier to look at than when its filled
with 1.043848974e-12 everywhere&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
function roundmatrix(A::Array,rtol::Real)
    Ap=copy(A)
    for ii in 1:length(A)
        if abs(Ap[ii])&amp;lt;rtol
            Ap[ii]=0
        end
    end
    return Ap;
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
## Here we create a random symmetric matrix
function makeA(n::Int)
    A=randn(n,n);
    for ii in 1:n
        A[ii,1:ii]=transpose(A[1:ii,ii])
    end
    V=eye(n) #initializing the orthogonal transformation
    return A,copy(A),V
end
## One A returned will be stored to compare initial and final
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now on to the rotations!&lt;/p&gt;

&lt;p&gt;We don’t always want to compute the eigenvectors, so those are in the optional entries slot.
Both tell the function to compute the vectors with &lt;code&gt;computeV=true&lt;/code&gt;
and input the &lt;code&gt;V=V&lt;/code&gt; after the semicolon.&lt;/p&gt;

&lt;p&gt;```julia
function Rotate(A::Array,p::Int,q::Int; computeV=false, V::Array=eye(1))
    θ=(A[q,q]-A[p,p])/(2*A[p,q]);
    t=sign(θ)/(abs(θ)+sqrt(θ^2+1));&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;c=1/sqrt(t^2+1)
s=t*c
τ=s/(1+c)

l=size(A)[1]
Ap=copy(A[:,p])
Aq=copy(A[:,q])
for r in 1:l
    A[r,p]=Ap[r]-s*(Aq[r]+τ*Ap[r])
    A[r,q]=Aq[r]+s*(Ap[r]-τ*Aq[r])

    A[p,r]=A[r,p]
    A[q,r]=A[r,q]
end
A[p,q]=0
A[q,p]=0
A[p,p]=Ap[p]-t*Aq[p]
A[q,q]=Aq[q]+t*Aq[p]

if computeV==true
    Vp=copy(V[:,p])
    Vq=copy(V[:,q])
    for r in 1:l
        V[r,p]=c*Vp[r]-s*Vq[r]
        V[r,q]=s*Vp[r]+c*Vq[r]
    end
    return A,V
else
    return A;
end end ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function performs one sweep&lt;/p&gt;

&lt;p&gt;```julia&lt;/p&gt;

&lt;p&gt;function Sweep(A;compV=false,V=eye(1))
    n=size(A)[1]
    for ii in 2:n
        for jj in 1:(ii-1) ## Just over one triangle
            if compV==false
                A=Rotate(A,ii,jj)
            else
                A,V=Rotate(A,ii,jj;computeV=true,V=V);
            end
        end
    end&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;if compV==false
    return A
else
    return A,V
end end ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just creating some size of matrix&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
A,A0,V=makeA(5);
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
## keep evaluating for a couple iterations
## watch how it changes
A,V=Sweep(A;compV=true,V=V);
roundmatrix(A,1e-10),A,V,convergence(A)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This output is after several sweeps&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    (
    5x5 Array{Float64,2}:
     -1.59942  0.0       0.0       0.0      0.0
      0.0      1.03678   0.0       0.0      0.0
      0.0      0.0      -0.823094  0.0      0.0
      0.0      0.0       0.0       3.09433  0.0
      0.0      0.0       0.0       0.0      1.3409,

    5x5 Array{Float64,2}:
     -1.59942      5.1314e-30    2.32594e-36  -9.54088e-49  -1.22782e-53
      5.1314e-30   1.03678       2.65014e-38   9.13791e-56   6.64996e-67
      2.32594e-36  2.65014e-38  -0.823094     -9.56652e-61   2.08002e-92
     -9.54088e-49  9.13791e-56  -9.56652e-61   3.09433       0.0
     -1.22782e-53  6.64996e-67   2.08002e-92   0.0           1.3409     ,

    5x5 Array{Float64,2}:
      0.0537334   0.0599494  -0.735228  0.139      0.658511
      0.310018    0.612957   -0.14049   0.611348  -0.367001
      0.759653   -0.475834    0.264118  0.282571   0.216575
     -0.480405   -0.546544   -0.132383  0.644217  -0.194831
     -0.305189    0.30913     0.593648  0.33477    0.588905,

    2.6331310238375346e-59)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compare the Optimized LAPLACK routine to your results&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
eig(A0)
&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      ([-1.599424470672961,-0.8230937166650976,1.0367806031602211,
      1.3408963512476402,3.0943321944116593],
      5x5 Array{Float64,2}:
       -0.0537334   0.735228   0.0599494  -0.658511  -0.139
       -0.310018    0.14049    0.612957    0.367001  -0.611348
       -0.759653   -0.264118  -0.475834   -0.216575  -0.282571
        0.480405    0.132383  -0.546544    0.194831  -0.644217
        0.305189   -0.593648   0.30913    -0.588905  -0.33477 )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;julia
## A good check to make sure V is an orthonomal transformation
roundmatrix(V*A*transpose(V)-A0,1e-12)
&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      5x5 Array{Float64,2}:
       0.0  0.0  0.0  0.0  0.0
       0.0  0.0  0.0  0.0  0.0
       0.0  0.0  0.0  0.0  0.0
       0.0  0.0  0.0  0.0  0.0
       0.0  0.0  0.0  0.0  0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How long does it take to make a Sweep?
How much memory will the computation take?
This is dependent on how large the matrix is, and determines whether or not we
want to use this algorithm.&lt;/p&gt;

&lt;p&gt;```julia&lt;/p&gt;

&lt;p&gt;A,A0,V=makeA(10);
@time Sweep(A);
A,A0,V=makeA(20);
@time Sweep(A);
A,A0,V=makeA(100);
@time Sweep(A);
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  0.000028 seconds (320 allocations: 30.469 KB)
  0.000099 seconds (1.33 k allocations: 187.266 KB)
  0.007413 seconds (34.66 k allocations: 17.448 MB, 14.20% gc time)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In addition to time per sweep, we need to know how many sweeps we need to run. So again we run it on a 10x10, 20x20, and 100x100. The efficiency of the algorithm would get a lot worse if we have to sweep the 100x100 a bunch of times.&lt;/p&gt;

&lt;p&gt;```julia
A10,Ap10,V=makeA(10);
A20,Ap20,V=makeA(20);
A100,Ap100,V=makeA(100);
nsweep=collect(1:7);
conv10=zeros(7)
conv20=zeros(7)
conv100=zeros(7)
for i in nsweep
    A10=Sweep(A10)
    A20=Sweep(A20)
    A100=Sweep(A100)
    conv10[i]=convergence(A10)
    conv20[i]=convergence(A20)
    conv100[i]=convergence(A100)
end&lt;/p&gt;

&lt;p&gt;[nsweep conv10/10 conv20/20 conv100/100]
```&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;7x4 Array{Float64,2}:
 1.0  1.10944       2.43759      14.6644
 2.0  0.105628      0.312076      2.87182
 3.0  0.000265288   0.017073      0.498082
 4.0  6.64324e-9    0.000119472   0.0390564
 5.0  4.05463e-18   3.56679e-11   0.00133833
 6.0  3.17274e-42   1.96318e-23   6.07661e-7
 7.0  6.76289e-110  4.07871e-49   3.98102e-13
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Well, so we’ve seen how to do one form of exact diagonalization that works, but doesn’t scale very well up to 100x100 matrices.  So stay tuned for the Householder method, hopefully coming up soon.&lt;/p&gt;

&lt;p&gt;Until then, happy computing :)&lt;/p&gt;
</description>
        <link>/M4/numerics/Jacobi-Transformation.html</link>
        <guid isPermaLink="true">/M4/numerics/Jacobi-Transformation.html</guid>
        
        <category>Exact Diagonalization</category>
        
        
        <category>numerics</category>
        
      </item>
    
      <item>
        <title>Atomic Orbitals Pt. 2</title>
        <description>&lt;p&gt;&lt;b&gt;Prerequiresites:&lt;/b&gt; Quantum Mechanics course&lt;/p&gt;

&lt;p&gt;If you haven’t read it already, check out &lt;a href=&quot;/M4/prerequisites/Atomic-Orbitals.html&quot;&gt;Atomic Orbitals Pt. 1&lt;/a&gt;.  Today, we try and make some prettier pictures. GLVisualize is quite a beautiful package, but not entirely the easiest to use at this point with some not so consistent documentation.&lt;/p&gt;

&lt;p&gt;To add this package:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
Pkg.add(&quot;GLVisualize&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;and test with:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
Pkg.test(&quot;GLVisualize&quot;)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;But, other steps may be necessary to get the package working.  On a Mac, I was required to install the Homebrew.jl package.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
#Pkg.update();
#Pkg.add(&quot;GSL&quot;);
using GSL;
using GLVisualize;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
a0=1; #for convenience, or 5.2917721092(17)×10−11 m&lt;/p&gt;

&lt;h1 id=&quot;the-unitless-radial-coordinate&quot;&gt;The unitless radial coordinate&lt;/h1&gt;
&lt;p&gt;ρ(r,n)=2r/(n*a0);&lt;/p&gt;

&lt;h1 id=&quot;the--dependence&quot;&gt;The θ dependence&lt;/h1&gt;
&lt;p&gt;function Pmlh(m::Int,l::Int,θ::Real)
    return (-1.0)^m *sf_legendre_Plm(l,m,cos(θ));
end&lt;/p&gt;

&lt;h1 id=&quot;the--and--dependence&quot;&gt;The θ and ϕ dependence&lt;/h1&gt;
&lt;p&gt;function Yml(m::Int,l::Int,θ::Real,ϕ::Real)
    return  (-1.0)^m&lt;em&gt;sf_legendre_Plm(l,abs(m),cos(θ))&lt;/em&gt;e^(im&lt;em&gt;m&lt;/em&gt;ϕ)
end&lt;/p&gt;

&lt;h1 id=&quot;the-radial-dependence&quot;&gt;The Radial dependence&lt;/h1&gt;
&lt;p&gt;function R(n::Int,l::Int,ρ::Real)
    if isapprox(ρ,0)
        ρ=.001
    end
     return sf_laguerre_n(n-l-1,2&lt;em&gt;l+1,ρ)&lt;/em&gt;e^(-ρ/2)*ρ^l
end&lt;/p&gt;

&lt;h1 id=&quot;a-normalization-this-is-dependent-on-the-choice-of-polynomial-representation&quot;&gt;A normalization: This is dependent on the choice of polynomial representation&lt;/h1&gt;
&lt;p&gt;function norm(n::Int,l::Int)
    return sqrt((2/n)^3 * factorial(n-l-1)/(2n*factorial(n+l)))
end&lt;/p&gt;

&lt;h1 id=&quot;generates-an-orbital-funtion-of-r-for-a-specificied-nlm&quot;&gt;Generates an Orbital Funtion of (r,θ,ϕ) for a specificied n,l,m.&lt;/h1&gt;
&lt;p&gt;function Orbital(n::Int,l::Int,m::Int)
    if (l&amp;gt;n)    # we make sure l and m are within proper bounds
        throw(DomainError())
    end
    if abs(m)&amp;gt;l
       throw(DomainError())
    end
    psi(ρ,θ,ϕ)=norm(n, l)&lt;em&gt;R(n,l,ρ)&lt;/em&gt;Yml(m,l,θ,ϕ);
    return psi
end&lt;/p&gt;

&lt;h1 id=&quot;we-will-calculate-is-spherical-coordinates-but-plot-in-cartesian-so-we-need-this-array-conversion&quot;&gt;We will calculate is spherical coordinates, but plot in cartesian, so we need this array conversion&lt;/h1&gt;
&lt;p&gt;function SphtoCart(r::Array,θ::Array,ϕ::Array)
    x=r.&lt;em&gt;sin(θ).&lt;/em&gt;cos(ϕ);
    y=r.&lt;em&gt;sin(θ).&lt;/em&gt;sin(ϕ);
    z=r.*cos(θ);
    return x,y,z;
end&lt;/p&gt;

&lt;p&gt;function CarttoSph(x::Array,y::Array,z::Array)
    r=sqrt(x.^2+y.^2+z.^2);
    θ=acos(z./r);
    ϕ=atan(y./x);
    return r,θ,ϕ;
end&lt;/p&gt;

&lt;p&gt;“Defined Helper Functions”
```&lt;/p&gt;

&lt;p&gt;Here, create a square cube, and convert those positions over to spherical coordinates.&lt;/p&gt;

&lt;p&gt;```julia
range=-10:.5:10
x=collect(range);
y=collect(range);
z=collect(range);
N=length(x);
xa=repeat(x,outer=[1,N,N]);
ya=repeat(transpose(y),outer=[N,1,N]);
za=repeat(reshape(z,1,1,N),outer=[N,N,1]);
println(“created x,y,z”)&lt;/p&gt;

&lt;p&gt;r,θ, ϕ=CarttoSph(xa,ya,za);
println(“created r,θ,ϕ”)
```&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
Ψ=Orbital(3,2,-1)
Ψp=Orbital(3,1,0)
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
Ψv = zeros(Float32,N,N,N);
ϕv = zeros(Float32,N,N,N);
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
for nn in 1:N
    for jj in 1:N
        for kk in 1:N
            val=Ψ(ρ(r[nn,jj,kk],2),θ[nn,jj,kk],ϕ[nn,jj,kk]);
            #val+=Ψp(ρ(r[nn,jj,kk],2),θ[nn,jj,kk],ϕ[nn,jj,kk]);
            Ψv[nn,jj,kk]=convert(Float32,abs(val));
            ϕv[nn,jj,kk]=convert(Float32,angle(val));
        end
    end
end&lt;/p&gt;

&lt;p&gt;mid=round(Int,(N-1)/2+1);
Ψv[mid,mid,:]=Ψv[mid+1,mid+1,:]; # the one at the center diverges
Ψv=(Ψv-minimum(Ψv))/(maximum(Ψv)-minimum(Ψv) );
```&lt;/p&gt;

&lt;p&gt;```julia
w,r = glscreen()&lt;/p&gt;

&lt;p&gt;robj=visualize(Ψv)&lt;/p&gt;

&lt;h1 id=&quot;choose-this-one-for-surfaces-of-constant-of-intensity&quot;&gt;choose this one for surfaces of constant of intensity&lt;/h1&gt;
&lt;p&gt;view(visualize(robj[:intensities],:iso))&lt;/p&gt;

&lt;h1 id=&quot;choose-this-for-a-block-of-3d-density&quot;&gt;choose this for a block of 3D density&lt;/h1&gt;
&lt;p&gt;#view(visualize(Ψv))
r()
```&lt;/p&gt;

&lt;h2 id=&quot;p-orbital&quot;&gt;2p Orbital&lt;/h2&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/2p_spaceb.png&quot; alt=&quot;2p&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;2p Orbital block showing the density of the wavefunction.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/2p_surface.png&quot; alt=&quot;2p&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;2p Orbital shown via isosurface.&lt;/p&gt;
    
&lt;/div&gt;

&lt;h2 id=&quot;d-orbitals&quot;&gt;3d orbitals&lt;/h2&gt;
&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/3d0_surface.png&quot; alt=&quot;3d0&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;3dz2 Orbital shown via isosurface. This corresponds to $n=3$, $l=2$, $m=0$.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/3d-1_surface.png&quot; alt=&quot;3dm1&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;A 3d Orbital shown via isosurface. This corresponds to $n=3$, $l=2$, $m=-1$. This is not one of the canonical images, but instead an $m$ shape.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/3d2-2_spaceb.png&quot; alt=&quot;3dxy&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;3dxy (x2-y2) orbital shown in density.  This is the sum of an $m=-2$ and $m=2$ state, for $n=3,l=2$. &lt;/p&gt;
    
&lt;/div&gt;

&lt;h2 id=&quot;p&quot;&gt;3p&lt;/h2&gt;
&lt;p&gt;In order to get this 3p surface image to come out correctly, I used the square root of the values instead in order to be able to see the much fainter outer lobe.&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/3p_surface.png&quot; alt=&quot;3p&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;3p surface plot.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals2/3p_spaceb.png&quot; alt=&quot;3p&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;3p space plot.&lt;/p&gt;
    
&lt;/div&gt;

</description>
        <link>/M4/prerequisites/Atomic-Orbitals2.html</link>
        <guid isPermaLink="true">/M4/prerequisites/Atomic-Orbitals2.html</guid>
        
        <category>Quantum</category>
        
        
        <category>prerequisites</category>
        
      </item>
    
      <item>
        <title>Atomic Orbitals</title>
        <description>&lt;p&gt;&lt;b&gt;Prerequiresites:&lt;/b&gt; Quantum Mechanics course&lt;/p&gt;

&lt;p&gt;Electrons around a nucleus.  Do they look like little well behaved planets orbiting a sun?&lt;/p&gt;

&lt;p&gt;NOPE!&lt;/p&gt;

&lt;p&gt;We get spread out blobs in special little patterns called orbitals.  Here, we will look at their shapes and properties a bit.  Today we will look at graphs in 1D and 2D, but the next post, &lt;a href=&quot;/M4/prerequisites/Atomic-Orbitals2.html&quot;&gt;Atomic Orbitals Pt. 2&lt;/a&gt;, uses a fancy, but slightly unstable plotting package, GLVisualize to generate some 3D plots.&lt;/p&gt;

&lt;p&gt;The Hamiltonian for our problem is:&lt;/p&gt;

&lt;p&gt;\begin{equation}
{\cal H}\Psi(\mathbf{x}) =\left[ -\frac{\hbar}{2 m} \nabla^2 - \frac{Z e^2}{4 \pi \epsilon_0 r}\right]\Psi(\mathbf{x}) = E \Psi(\mathbf{x})
\end{equation}
with
\begin{equation}
\nabla^2= \frac{1}{r^2}\frac{\partial}{\partial r} \left(
r^2 \frac{\partial}{\partial r}
\right)+
\frac{1}{r^2 \sin \theta} \frac{\partial}{\partial \theta} \left(
\sin \theta \frac{\partial}{\partial \theta}
\right)+
\frac{1}{r^2 \sin^2 \theta} \frac{\partial^2}{\partial \phi^2}
\end{equation}&lt;/p&gt;

&lt;p&gt;To solve this problem, we begin by guessing a solution with separated &lt;i&gt;radial&lt;/i&gt; and &lt;i&gt;angular&lt;/i&gt; variables,
\begin{equation}
\Psi(\mathbf{x}) = R(r) \Theta ( \theta,\phi)
\end{equation}&lt;/p&gt;

&lt;p&gt;\begin{equation}
\frac{E r^2 R(r)}{2r R^{\prime}(r) + r^2 R^{\prime \prime}(r)}=
\frac{\left( \frac{1}{\sin \theta} \frac{\partial}{\partial \theta} \left(
\sin \theta \frac{\partial \Theta(\theta,\phi)}{\partial \theta}
\right)+
\frac{1}{\sin^2 \theta} \frac{\partial^2 \Theta(\theta,\phi)}{\partial \phi^2}\right)      }{\Theta( \theta, \phi)}
=C
\end{equation}&lt;/p&gt;

&lt;p&gt;Instead of going into the precise mechanisms of solving those two separate equations here, trust for now that they follow standard special functions, the associated &lt;i&gt;Legendre polynomial&lt;/i&gt; and the generalized &lt;i&gt;Laguerre polynomial&lt;/i&gt;.  Try a standard quantum mechanics textbook for more information about this.&lt;/p&gt;

&lt;p&gt;\begin{equation}
Y^m_l(θ,ϕ) = (-1)^m e^{i m \phi} P^m_l (\cos(θ))
\end{equation}
where $P^m_l (\cos (\theta))$ is the associated Legendre polynomial.&lt;/p&gt;

&lt;p&gt;\begin{equation}
 R^{n,l} ( \rho ) = \rho ^l e^{- \rho  /2} L^{2 l+1}_{n-l-1} ( \rho )
\end{equation}
where $L^{2 l+1}_{n-l-1}(\rho)$ is the generalized Laguerre polynomial.&lt;/p&gt;

&lt;p&gt;\begin{equation}
    \rho=\frac{2r}{n a_0}
\end{equation}&lt;/p&gt;

&lt;p&gt;\begin{equation}
    N=\sqrt{\left(\frac{2}{n}\right)^3 \frac{(n-l-1)}{2n(n+l)!}}
\end{equation}&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
#Pkg.update();
#Pkg.add(&quot;GSL&quot;);
#Pkg.add(&quot;PyPlot&quot;);
using GSL;    #GSL holds the special functions
using PyPlot;
&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&quot;cell-to-evaluate&quot;&gt;Cell to Evaluate&lt;/h4&gt;
&lt;p&gt;What’s below is a bunch of definitions that makes our calculations easier later on.  Here I utilize the GNU scientific library, GSL imported above, to calculate the special functions.&lt;/p&gt;

&lt;div class=&quot;progtip&quot;&gt;
&lt;h3 color=&quot;black&quot;&gt; Programming Tip!&lt;/h3&gt;
&lt;p&gt;Even though it&#39;s not necessary, specifying the type of inputs to a function through &lt;code&gt;m::Int&lt;/code&gt; helps prevent improper inputs and allows the compiler to perform additional optimizations.  Julia also implements &lt;i&gt;abstract types&lt;/i&gt;, so we don&#39;t have to specify the exact type of Int.  Real allows a numerical, non-complex type.&lt;/p&gt;
&lt;p&gt;
Type Greek characters in Jupyter notebooks via LaTeX syntax,  e.g. \alpha+tab&lt;/p&gt;
&lt;p&gt;
The function &lt;code&gt;Orbital&lt;/code&gt; throws &lt;code&gt;DomainError()&lt;/code&gt; when &lt;code&gt;l&lt;/code&gt; or &lt;code&gt;m&lt;/code&gt; do not obey their bounds.  Julia supports a wide variety of easy to use error messages.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;```julia
a0=1; #for convenience, or 5.2917721092(17)×10−11 m&lt;/p&gt;

&lt;h1 id=&quot;the-unitless-radial-coordinate&quot;&gt;The unitless radial coordinate&lt;/h1&gt;
&lt;p&gt;ρ(r,n)=2r/(n*a0);&lt;/p&gt;

&lt;h1 id=&quot;the--dependence&quot;&gt;The θ dependence&lt;/h1&gt;
&lt;p&gt;function Pmlh(m::Int,l::Int,θ::Real)
    return (-1.0)^m *sf_legendre_Plm(l,m,cos(θ));
end&lt;/p&gt;

&lt;h1 id=&quot;the--and--dependence&quot;&gt;The θ and ϕ dependence&lt;/h1&gt;
&lt;p&gt;function Yml(m::Int,l::Int,θ::Real,ϕ::Real)
    return  (-1.0)^m&lt;em&gt;sf_legendre_Plm(l,m,cos(θ))&lt;/em&gt;e^(im&lt;em&gt;m&lt;/em&gt;ϕ)
end&lt;/p&gt;

&lt;h1 id=&quot;the-radial-dependence&quot;&gt;The Radial dependence&lt;/h1&gt;
&lt;p&gt;function R(n::Int,l::Int,ρ::Real)
    if isapprox(ρ,0)
        ρ=.01
    end
     return sf_laguerre_n(n-l-1,2&lt;em&gt;l+1,ρ)&lt;/em&gt;e^(-ρ/2)*ρ^l
end&lt;/p&gt;

&lt;h1 id=&quot;a-normalization-this-is-dependent-on-the-choice-of-polynomial-representation&quot;&gt;A normalization: This is dependent on the choice of polynomial representation&lt;/h1&gt;
&lt;p&gt;function norm(n::Int,l::Int)
    return sqrt((2/n)^3 * factorial(n-l-1)/(2n*factorial(n+l)))
end&lt;/p&gt;

&lt;h1 id=&quot;generates-an-orbital-function-of-r-for-a-specified-nlm&quot;&gt;Generates an Orbital function of (r,θ,ϕ) for a specified n,l,m.&lt;/h1&gt;
&lt;p&gt;function Orbital(n::Int,l::Int,m::Int)
    if l&amp;gt;n    # we make sure l and m are within proper bounds
        throw(DomainError())
    end
    if abs(m)&amp;gt;l
        throw(DomainError())
    end
    psi(ρ,θ,ϕ)=norm(n, l)&lt;em&gt;R(n,l,ρ)&lt;/em&gt;Yml(m,l,θ,ϕ);
    return psi
end&lt;/p&gt;

&lt;h1 id=&quot;we-will-calculate-is-spherical-coordinates-but-plot-in-cartesian-so-we-need-this-array-conversion&quot;&gt;We will calculate is spherical coordinates, but plot in Cartesian, so we need this array conversion&lt;/h1&gt;
&lt;p&gt;function SphtoCart(r::Array,θ::Array,ϕ::Array)
    x=r.&lt;em&gt;sin(θ).&lt;/em&gt;cos(ϕ);
    y=r.&lt;em&gt;sin(θ).&lt;/em&gt;sin(ϕ);
    z=r.*cos(θ);
    return x,y,z;
end&lt;/p&gt;

&lt;p&gt;function CarttoSph(x::Array,y::Array,z::Array)
    r=sqrt(x.^2+y.^2+z.^2);
    θ=acos(z./r);
    ϕ=atan(y./x);
    return r,θ,ϕ;
end&lt;/p&gt;

&lt;p&gt;“Defined Helper Functions”
```&lt;/p&gt;

&lt;h4 id=&quot;parameters&quot;&gt;Parameters&lt;/h4&gt;
&lt;p&gt;Grid parameters:
You might need to change &lt;code&gt;rmax&lt;/code&gt; to be able to view higher $n$ orbitals.&lt;/p&gt;

&lt;p&gt;Remember that
\begin{equation}
0&amp;lt;n \;\;\;\;\; \;\;\;\; 0 \leq l &amp;lt; n \;\;\;\;\; \;\;\;\; -l \leq m \leq l
\;\;\;\;\; \;\;\;\; n,l,m \in {\cal Z}
\end{equation}&lt;/p&gt;

&lt;p&gt;```julia
# Grid Parameters
rmin=.05
rmax=10
Nr=100 #Sampling frequency
Nθ=100
Nϕ=100&lt;/p&gt;

&lt;h1 id=&quot;choose-which-orbital-to-look-at&quot;&gt;Choose which Orbital to look at&lt;/h1&gt;
&lt;p&gt;n=3;
l=1;
m=0;
“Defined parameters”
```&lt;/p&gt;

&lt;p&gt;```julia
#Linear Array of spherical coordinates
r=collect(linspace(rmin,rmax,Nr));
ϕ=collect(linspace(0,2π,Nθ));
θ=collect(linspace(0,π,Nϕ));
#3D arrays of spherical coordinates, in order r,θ,ϕ
ra=repeat(r,outer=[1,Nθ,Nϕ]);
θa=repeat(transpose(θ),outer=[Nr,1,Nϕ]);
ϕa=repeat(reshape(ϕ,1,1,Nϕ),outer=[Nr,Nθ,1]);&lt;/p&gt;

&lt;p&gt;x,y,z=SphtoCart(ra,θa,ϕa);
```&lt;/p&gt;

&lt;p&gt;Though I could create a wrapped up function with &lt;code&gt;Orbital(n,l,m)&lt;/code&gt; and evaluate that at each point, the below evaluation takes advantage of the separability of the solution with respect to spherical dimensions.  The special functions, especially for higher modes, take time to calculate, and the fewer calls to GSL, the faster the code will run.  Therefore, this implementation copies over radial and angular responses.&lt;/p&gt;

&lt;p&gt;```julia
Ψ=zeros(Float64,Nr,Nϕ,Nθ)
θd=Int64(round(Nθ/2))  ## gives approximately the equator.  Will be useful later&lt;/p&gt;

&lt;p&gt;p1=Pmlh(m,l,θ[1]);
p2=exp(im&lt;em&gt;m&lt;/em&gt;ϕ[1]);
for i in 1:Nr
    Ψ[i,1,1]=norm(n,l)&lt;em&gt;R(n,l,ρ(r[i],n))&lt;/em&gt;p1*p2;
end&lt;/p&gt;

&lt;p&gt;for j in 1:Nθ
    Ψ[:,j,1]=Ψ[:,1,1]*Pmlh(m,l,θ[j])/p1;
end&lt;/p&gt;

&lt;p&gt;for k in 1:Nϕ
    Ψ[:,:,k]=Ψ[:,:,1]&lt;em&gt;exp(im&lt;/em&gt;m*ϕ[k])/p2;
end
```&lt;/p&gt;

&lt;p&gt;```julia
pygui(false)
xlabel(“θ”)
ylabel(“Ψ”)
title(“Wavefunction for n= $n ,l= $l ,m= $m “)&lt;/p&gt;

&lt;p&gt;annotate(“l= $l Angular Node”,
xy=[π/2;0],
xytext=[π/2+.1;.02],
xycoords=”data”,
arrowprops=Dict(“facecolor”=&amp;gt;”black”))&lt;/p&gt;

&lt;p&gt;plot(θ,zeros(θ))
plot(θ,reshape(Ψ[50,:,1],100)) #reshape makes Ψ 1D
```&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals/angular1di.png&quot; alt=&quot;2p Angle Slice&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;A slice along the θ plane showing an angular node for the 2p orbital.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;```julia
pygui(false)
xlabel(“r”)
ylabel(“Ψ”)
title(“Wavefunction for n= $n ,l= $l ,m= $m “)&lt;/p&gt;

&lt;p&gt;plot(r,zeros(r))
plot(r,reshape(Ψ[:,50,1],100)) #reshape makes Ψ 1D
```
&lt;!-- _includes/image.html --&gt;
&amp;lt;div class=&quot;image-wrapper&quot; &amp;gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;img src=&quot;/M4/Images/Orbitals/radial1di.png&quot; alt=&quot;3p Radial Slice&quot; /&amp;gt;


    &amp;lt;p class=&quot;image-caption&quot;&amp;gt;A slice along the radial plane showing a radial node in the 3p orbital.&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
#rap=squeeze(ra[:,:,50],3)
#θap=squeeze(θa[:,:,50],3)
#ϕap=squeeze(ϕa[:,:,50],3)
#Ψp=squeeze(Ψ[:,:,50],3)
rap=ra[:,:,50]
θap=θa[:,:,50]
ϕap=ϕa[:,:,50]
Ψp=Ψ[:,:,50]
xp,yp,zp=SphtoCart(rap,θap,ϕap);
pygui(false)
xlabel(&quot;x&quot;)
ylabel(&quot;z&quot;)
title(&quot;ϕ-slice of Ψ for n=$n, l=$l, m=$m&quot;)
pcolor(xp[:,:],zp[:,:],Ψp[:,:],cmap=&quot;coolwarm&quot;)
colorbar()
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals/angular2di.png&quot; alt=&quot;3p in 2d&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Slice of a 3p orbital in the x and z plane.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/Orbitals/angular2d2i.png&quot; alt=&quot;3dz2 in 2d&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Slice of a 3dz2 orbital in the x and z plane.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;Don’t forget to check out &lt;a href=&quot;/M4/prerequisites/Atomic-Orbitals2.html&quot;&gt;Atomic Orbitals Pt. 2&lt;/a&gt;!&lt;/p&gt;
</description>
        <link>/M4/prerequisites/Atomic-Orbitals.html</link>
        <guid isPermaLink="true">/M4/prerequisites/Atomic-Orbitals.html</guid>
        
        <category>Quantum</category>
        
        
        <category>prerequisites</category>
        
      </item>
    
      <item>
        <title>Quantum Harmonic Oscillator</title>
        <description>&lt;p&gt;&lt;b&gt;Prerequiresites:&lt;/b&gt; Quantum Mechanics course&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Slinkies&lt;/b&gt;. They started out as toys.  I still have one to play with on my desk.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Rubber bands&lt;/b&gt; What was once something useful, is now a wonderful projectile weapon.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Swings&lt;/b&gt; I still love them, but people seem to not make them in adult sizes for some reason.&lt;/p&gt;

&lt;p&gt;A person’s perception of these objects starts to change as they enter their first physics class. Even in that beginning class of classical mechanics, the problems are filled with harmonic oscillators, like slinkies, rubber bands, or swings, which exert a force proportional to their displacement&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
F=-kx
&lt;/script&gt;

&lt;p&gt;and therefore a quadratic potential&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
V(x)=k x^2
&lt;/script&gt;

&lt;p&gt;This is all extremely fun and useful in the classical regime, but we add Quantum Mechanics to the mix, and LOW AND BEHOLD! we have one of the few exactly solvable models in Quantum Mechanics. Moreso, this solution demonstrates some extremely important properties of quantum mechanical systems.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The Hamiltonian&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
    {\cal H}= \frac{p^2}{2 m} + \frac{1}{2} m \omega ^2 x^2
&lt;/script&gt;

&lt;p&gt;&lt;b&gt; The Solution&lt;/b&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
    \Psi (x) = \frac{1}{\sqrt{2^n n!}} \left(\frac{m \omega}{\hbar \pi}\right)^{1/4} \mathrm{e}^{-m \omega x^2/2 \hbar}  H_n \left( \sqrt{\frac{m \omega}{\hbar}} x \right)
&lt;/script&gt;

&lt;p&gt;Today, I just intend to present the form of the solution, calculate this equation numerically, and visualize the results.  If you wish to know how the equation is derived, you can find a standard quantum mechanics textbook, or stay tuned till I manage to write it up.&lt;/p&gt;

&lt;h3 id=&quot;physicists-hermite-polynomials&quot;&gt;Physicists’ Hermite Polynomials&lt;/h3&gt;
&lt;p&gt;Note: These are not the same as the “probabilists’ Hermite Polynomial”. The two functions differ by scaling factors.&lt;/p&gt;

&lt;p&gt;Physicists’ Hermite polynomials are defined as eigenfunctions for the differential equation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
u^{\prime \prime}-2xu^{\prime} = -2 \lambda u
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
H_n(x) = (-1)^n \mathrm{e}^{x^2} \frac{\mathrm{d}^n}{\mathrm{d}x^n}
\left( e^{-x^2} \right)
&lt;/script&gt;

&lt;p&gt;I leave it as an exercise to the reader to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;demonstrate orthogonality with respect to the measure $e^{-x^2}$, i.e.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
\int_{-\infty}^{\infty} H_m(x) H_n(x) e^{-x^2} \mathrm{d}x = \sqrt{\pi} 2^n n! \delta_{mn}
&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;demonstrate completeness.  This means we can describe every function by a linear combination of Hermite polynomials, provided it is suitably well behaved.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Though a formula exists or calculating a function at $n$ directly, the most efficient method at low $n$ for calculating polynomials relies on recurrence relationships.  These recurrence relationships will also be quite handy if you ever need to show orthogonality, or expectation values.&lt;/p&gt;

&lt;h3 id=&quot;recurrence-relations&quot;&gt;Recurrence Relations&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
H_{n+1}(x) = 2xH_n(x) - H^{\prime}_n(x)
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
H^{\prime}_n (x) = 2n H_{n-1}(x)
&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;
H_{n+1}(x) = 2x H_n(x) - 2n H_{n-1}(x)
&lt;/script&gt;

&lt;pre&gt;&lt;code class=&quot;language-julia&quot;&gt;#Pkg.update();
#Pkg.add(&quot;PyPlot&quot;);
#Pkg.update()
#Pkg.add(&quot;Roots&quot;)
using Roots;
using PyPlot;
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;progtip&quot;&gt;
&lt;h3 color=&quot;black&quot;&gt; Programming Tip!&lt;/h3&gt;
Since Hermite polynomials are generated recursively, I wanted to generate and save all the functions up to a designated value at once.  In order to do so, I created an array, whose values are anonymous functions.
&lt;/div&gt;

&lt;p&gt;```julia
function GenerateHermite(n)
    Hermite=Function[]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;push!(Hermite,x-&amp;gt;1);
push!(Hermite,x-&amp;gt;2*x);

for ni in 3:n
    push!(Hermite,x-&amp;gt;2.*x.*Hermite[ni-1](x).-2.*n.*Hermite[ni-2](x))
end
return Hermite end ```
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s generate some Hermite polynomials and look at them.
&lt;b&gt; Make sure you don’t call a Hermite you haven’t generated yet!&lt;/b&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
Hermite=GenerateHermite(5)
&lt;/code&gt;
&amp;lt;div class=&quot;progtip&quot;&amp;gt;
&amp;lt;h3 color=&quot;black&quot;&amp;gt;Programming Tip!&amp;lt;/h3&amp;gt;
Since the Hermite polynomials, and the wavefunctions after them, are composed of anonymous functions, we need to use &lt;code&gt;map(f,x)&lt;/code&gt; in order to map the function &lt;code&gt;f&lt;/code&gt; onto the array &lt;code&gt;x&lt;/code&gt;.  Otherwise our polynomials only work on single values.
&amp;lt;/div&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
x=collect(-2:.01:2);
for j in 1:5
    plot(x,map(Hermite[j],x),label=&quot;H_$j (x)&quot;)
end
legend()
ylim(-50,50)
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/QHO/hermitesi.png&quot; alt=&quot;Hermite Polynomials&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;First few Hermite Polynomials&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;```julia
# Lets make our life easy and set all units to 1
m=1
ω=1
ħ=1&lt;/p&gt;

&lt;h1 id=&quot;finally-we-define-&quot;&gt;Finally, we define Ψ&lt;/h1&gt;
&lt;p&gt;Ψ(n,x)=1/sqrt(factorial(n)&lt;em&gt;2^n)&lt;/em&gt;(m&lt;em&gt;ω/(ħ&lt;/em&gt;π))^(1/4)&lt;em&gt;exp(-m&lt;/em&gt;ω&lt;em&gt;x^2/(2&lt;/em&gt;ħ))*Hermite&lt;a href=&quot;sqrt(m*ω/ħ)*x&quot;&gt;n&lt;/a&gt;
```&lt;/p&gt;

&lt;h3 id=&quot;finding-zeros&quot;&gt;Finding Zeros&lt;/h3&gt;
&lt;p&gt;The eigenvalue maps to the number of zeros in the wavefunction.  Below, I use Julia’s roots package to indentify roots on the interval from -3 to 3.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
zeds=Array{Array{Float64}}(1)
zeds[1]=[] #ground state has no zeros
for j in 2:4
    push!(zeds,fzeros(y-&amp;gt;Ψ(j,y),-3,3))
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
# AHHHHH! So Much code!
# Don’t worry; it’s all just plotting
x=collect(-3:.01:3)  #Set some good axes&lt;/p&gt;

&lt;p&gt;for j in 1:4    #how many do you want to view?
    plot(x,map(y-&amp;gt;Ψ(j,y),x)+j-1,label=”| $j &amp;gt;”)
    plot(x,(j-1)&lt;em&gt;ones(x),color=”black”)
    scatter(zeds[j],(j-1)&lt;/em&gt;ones(zeds[j]),marker=”o”,s=40)
end
plot(x,.5&lt;em&gt;m&lt;/em&gt;ω^2*x.^2,linestyle=”–“,label=”Potential”)&lt;/p&gt;

&lt;p&gt;scatter([],[],marker=”o”,s=40,label=”Zeros”)
xlabel(“x”)
ylabel(“Ψ+n”)
title(“Eigenstates of a Harmonic Osscilator”)
legend()
xlim(-3,3);
ylim(-.5,4.5);
```&lt;/p&gt;

&lt;h2 id=&quot;example-result&quot;&gt;Example Result&lt;/h2&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/QHO/eigenstatesi.png&quot; alt=&quot;Eigenstates&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Eigenstates of the Quantum Harmonic Osscillator&lt;/p&gt;
    
&lt;/div&gt;

&lt;h2 id=&quot;more-to-come&quot;&gt;More to come&lt;/h2&gt;
&lt;p&gt;This barely scratched the surface into the richness that can be seen in the quantum harmonic oscillator.  Here, we have developed a way for calculating the functions, and visualized the results.  Stay tuned to hear about ground state energy, ladder operators, and atomic trapping.&lt;/p&gt;
</description>
        <link>/M4/prerequisites/QHO.html</link>
        <guid isPermaLink="true">/M4/prerequisites/QHO.html</guid>
        
        <category>Quantum</category>
        
        
        <category>prerequisites</category>
        
      </item>
    
      <item>
        <title>Computationally Visualizing Crystals Pt. 2</title>
        <description>&lt;h4 id=&quot;christina-c-lee-github-albi3ro&quot;&gt;Christina C. Lee, github: albi3ro&lt;/h4&gt;

&lt;p&gt;&lt;b&gt;Prerequisites:&lt;/b&gt; &lt;a href=&quot;/M4/general/Crystal-Shapes.html&quot;&gt;Computationally Visualizing Crystals Pt. 1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Time to one-up the Bravais lattice from Part 1.  Many beautiful lattices don’t adhere to the “every site the same” policy.  They still repeat, but just take a little bit longer to get around to doing so.&lt;/p&gt;

&lt;p&gt;Take the Kagome Lattice below,&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/kagomesvg.png&quot; alt=&quot;kagome&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;A Kagome Lattice.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/kagomebasket.jpg&quot; alt=&quot;basket&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;A basket woven in the Japanese kagome style. &lt;sub&gt;Wikimedia commons&lt;/sub&gt;&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;If we look at the stars at the center of triangles, we can recognize a point triangular Bravais lattice.  Now each of those stars stands for a grouping of three sites in a &lt;i&gt;unit cell&lt;/i&gt;.  According to &lt;a href=&quot;http://chemwiki.ucdavis.edu/Physical_Chemistry/Physical_Properties_of_Matter/Phases_of_Matter/Solids/Unit_Cell&quot;&gt;Chem Wiki&lt;/a&gt;, a unit cell is:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A unit cell is the most basic and least volume consuming repeating structure of any solid. It is used to visually simplify the crystalline patterns solids arrange themselves in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I chose these triangles to be be the unit cells above and in my computational representation below, but can you think of any other ways to represent the unit cell?&lt;/p&gt;

&lt;p&gt;Turns out, there isn’t a unique way.  We can go further and define the &lt;i&gt;Wigner-Seitz&lt;/i&gt; unit cell, which uses the Bravais translations to pick out just ONE of the various possible definitions.&lt;/p&gt;

&lt;p&gt;In my line of work though, we often use either the easiest to write down, or the one that has the symmetries we want.&lt;/p&gt;

&lt;h3 id=&quot;introducing-some-lattice-options&quot;&gt;Introducing Some Lattice Options&lt;/h3&gt;

&lt;p&gt;You saw Kagome above.&lt;/p&gt;

&lt;p&gt;The options I’ve put in now are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;honeycomb&lt;/li&gt;
  &lt;li&gt;kagome&lt;/li&gt;
  &lt;li&gt;shuriken (a.k.a. square-Kagome)&lt;/li&gt;
  &lt;li&gt;diamond&lt;/li&gt;
  &lt;li&gt;pyrochlore&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The ones implemented here, except for diamond, are frustrated lattices that I work with in my research. Honeycomb is well known in condensed matter physics for being the structure of graphene. This is an extremely important material right now, though I work with it in terms of the Kitaev spin model (to be discussed at a later date). Kagome and pyrochlore are also popular models within my community.  The shuriken lattice is more uncommon, but gaining ground in the frustration community.&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/Shurikens.jpg&quot; alt=&quot;Shurikens&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Japanese Shurikens- a type of ninja fighting star. &lt;sub&gt;By kaex0r (http://www.flickr.com/photos/kaex0r414/191765028/) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons&lt;/sub&gt;&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;&lt;code&gt;julia
# importing our packages
Pkg.add(&quot;PyPlot&quot;);
Pkg.update();
using PyPlot;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;```julia
lattice=”shuriken”;&lt;/p&gt;

&lt;p&gt;Nx=3;
Ny=3;
Nz=1;
```&lt;/p&gt;

&lt;p&gt;```julia
# A cell to just evaluate
# This one sets the unit vectors (a,b,c) for the different unit cells
# Can you guess what a lattice will look like by looking at the vectors?
if(lattice==”honeycomb”) #also the graphite lattice
    d=2;
    Ncell=2;
    unit=[[0 0 0]
        [sqrt(3)/2 1/2 0]];
    a=[sqrt(3),0,0];
    b=[sqrt(3)/2,3/2,0];
    c=[0,0,1];
elseif(lattice==”kagome”)
    d=2;
    Ncell=3;
    unit=[[0 0 0]
          [1 0 0]
        [.5 sqrt(3)/2 0]];
    a=[2,0,0];       #Look familiar? Checkout pt from Pt. 1
    b=[1, sqrt(3), 0];
    c=[0,0,1];
elseif(lattice==”shuriken”)
    d=2;
    Ncell=6;
    unit=[[0 0 0]
          [.5 0 0]
          [0 .5 0]
          [.5 .5 0]
        [.5+.25&lt;em&gt;sqrt(3) .25 0]
        [.25 .5+.25&lt;/em&gt;sqrt(3) 0]];
    a=[.5+.5&lt;em&gt;sqrt(3),0,0];
    b=[0,.5+.5&lt;/em&gt;sqrt(3),0];
    c=[0,0,1];
elseif(lattice==”diamond”)
    d=3;
    Ncell=2;
    unit=[[0 0 0]
          [.25 .25 .25]];
    a=[.5,.5,0];    #Look familiar? Checkout fcc from Pt.1
    b=[.5,0,.5];
    c=[0,.5,.5];
elseif(lattice==”pyrochlore”)
    d=3;
    Ncell=4;
    unit=[[0 0 0]
        [.25 .25 0]
        [.25 0 .25]
        [0 .25 .25]];
    a=[.5,.5,0];
    b=[.5,0,.5];
    c=[0,.5,.5];&lt;/p&gt;

&lt;p&gt;else
    println(“Please have a correct lattice”)
end
“Cell finished”
```&lt;/p&gt;

&lt;h3 id=&quot;connections-to-bravais-lattices&quot;&gt;Connections to Bravais Lattices&lt;/h3&gt;

&lt;p&gt;If you look at some of the comments above, and checkout the basis vectors from &lt;a href=&quot;/M4/General/Crystal-Shapes.html&quot;&gt;&lt;i&gt;Crystal Shapes&lt;/i&gt;&lt;/a&gt;, like pt,
        \begin{equation}
            a=[1,0,0]\;\;\;\;\;\;\;\;\; b=[.5,\frac{\sqrt{3}}{2},0],
        \end{equation}
you’ll notice they’re the same except for a scaling factor.  This has to be true, since only 14 different patterns tile 3D space uniquely.&lt;/p&gt;

&lt;p&gt;```julia
# Another cell to just evaluate
# Here we set up some numbers and matrices for our computation
N=Nx&lt;em&gt;Ny&lt;/em&gt;Nz&lt;em&gt;Ncell;    #The total number of sites
aM=transpose(repeat(a,outer=[1,Ncell]));
bM=transpose(repeat(b,outer=[1,Ncell&lt;/em&gt;Nx])); #these allow us to copy an entire row or layer at once
cM=transpose(repeat(c,outer=[1,Ncell&lt;em&gt;Nx&lt;/em&gt;Ny]));&lt;/p&gt;

&lt;p&gt;X=Array{Float64}(N,3);  #where we store the positions
“Cell finished”
```&lt;/p&gt;

&lt;p&gt;```julia
# Another cell to just evaluate
# Here we are actually calculating the positions for every site
for i in 1:Nx    #for the first row
    X[Ncell&lt;em&gt;i-Ncell+1:Ncell&lt;/em&gt;i,:]=unit+(i-1)*aM;
end&lt;/p&gt;

&lt;p&gt;for j in 2:Ny    #copying the first row into the first layer
    X[Ncell&lt;em&gt;Nx&lt;/em&gt;(j-1)+(1:Ncell&lt;em&gt;Nx),:]=X[1:Ncell&lt;/em&gt;Nx,:]+(j-1)*bM;
end&lt;/p&gt;

&lt;p&gt;for j in 2:Nz    #copying the first layer into the entire cube
    X[Ncell&lt;em&gt;Ny&lt;/em&gt;Nx&lt;em&gt;(j-1)+(1:Ncell&lt;/em&gt;Nx&lt;em&gt;Ny),:]=X[1:Ncell&lt;/em&gt;Nx&lt;em&gt;Ny,:]+(j-1)&lt;/em&gt;cM;
end
“Cell finished”
```&lt;/p&gt;

&lt;p&gt;&lt;code&gt;julia
# 2D plotter
pygui(false)
w, h = plt[:figaspect](1)
figure(figsize=(w,h))
scatter(X[:,1],X[:,2])
&lt;/code&gt;&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/shurikenplot.png&quot; alt=&quot;Shuriken&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;3x3 Shuriken or Square-Kagome Lattice.&lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;&lt;code&gt;julia
# 3D plotter
pygui(false)
w, h = plt[:figaspect](1)
figure(figsize=(w,h))
areas=100*ones(length(X[:,1]))
scatter3D(X[:,1],X[:,2],X[:,3])
&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;perdy-pictures&quot;&gt;Perdy Pictures&lt;/h3&gt;
&lt;p&gt;From these plots, some 3D structures like the pyrochlore are hard to visualize.  So here’s a nice graphic I made that might help a little bit more.&lt;/p&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/pyrochloresvg4.png&quot; alt=&quot;Pyrochlore&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Hopefully this pyrochlore is a little easier to visualize than the pyplot version.  Took me long enough to make in inkscape.&lt;/p&gt;
    
&lt;/div&gt;

&lt;!-- _includes/image.html --&gt;
&lt;div class=&quot;image-wrapper&quot;&gt;
    
        &lt;img src=&quot;/M4/Images/MultiUnit/honeycomb.png&quot; alt=&quot;honeycomb&quot; /&gt;
    
    
        &lt;p class=&quot;image-caption&quot;&gt;Tikz produced Honeycomb.  Coloring indicative of the lattice description of the Kitaev model.  &lt;/p&gt;
    
&lt;/div&gt;

&lt;p&gt;The honeycomb, like several other lattices you see around here, is &lt;i&gt;bipartite&lt;/i&gt;.
You can see in my image that black sites are only next to white sites, and vice versa.
  This property can make the system much easier to work with.  What lattices are bipartite, and which ones aren’t?&lt;/p&gt;

&lt;p&gt;If you keep reading, these lattices will keep cropping up again and again.  I’ll probably throw in some new ones as well.&lt;/p&gt;

&lt;p&gt;Anyway, we will move onto some Quantum Mechanics to look at atomic orbitals soon!&lt;/p&gt;
</description>
        <link>/M4/general/MultiSite-Unit-Cells.html</link>
        <guid isPermaLink="true">/M4/general/MultiSite-Unit-Cells.html</guid>
        
        <category>Lattices</category>
        
        
        <category>general</category>
        
      </item>
    
  </channel>
</rss>
